{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Terraform Infrastructure as Code Portfolio Project <p>     Modular AWS Infrastructure with Terraform: Automated, Secure, and Scalable   </p> <p> </p>"},{"location":"#tech-stack","title":"Tech Stack","text":""},{"location":"#features","title":"Features","text":"<ul> <li>Modular Terraform configuration for AWS</li> <li>Automated provisioning and teardown</li> <li>Environment isolation (dev, staging, production)</li> <li>Git workflow automation with Git Flow</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>[!IMPORTANT] This project uses Devbox to provide a consistent development environment.</p> <ol> <li> <p>Install Docker Docker installation guide</p> </li> <li> <p>Install Devbox Devbox installation guide</p> </li> <li> <p>Clone the repository <pre><code>git clone https://github.com/sean-njela/terraform-demo.git\ncd terraform-demo\n</code></pre></p> </li> <li> <p>Start Devbox shell</p> </li> </ol> <pre><code>devbox shell\n</code></pre> <p>First run may take several minutes to install tools.</p> <ol> <li>Configure AWS IAM    The project uses Terraform Cloud. Ensure your IAM role is set up.    See setup docs.</li> </ol>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>task setup\ntask status   # check if everything is running\ntask dev      # start development stack\ntask cleanup-dev\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is in docs. Run locally with:</p> <pre><code>task docs\n</code></pre> <p>Then open: http://127.0.0.1:8030/</p>"},{"location":"#tasks-automation","title":"Tasks (Automation)","text":"<p>[!IMPORTANT] This project is designed for a simple, one-command setup. All necessary actions are orchestrated through <code>Taskfile.yml</code>.</p> <p>The <code>Taskfile.gitflow.yml</code> provides a structured Git workflow using Git Flow. This helps in managing features, releases, and hotfixes in a standardized way. To run these tasks just its the same as running any other task. Using gitflow is optional.</p> <p>To see all tasks:</p> <pre><code>task --list-all\n</code></pre> <p>If you do not want the gitflow tasks, you can remove the <code>Taskfile.gitflow.yml</code> file and unlink it from the <code>Taskfile.yml</code> file (remove the <code>includes</code> section). If you cannot find the section use CTRL + F to search for <code>Taskfile.gitflow.yml</code>.</p>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Core infrastructure setup</li> <li> Extend CI/CD integration</li> <li> Add monitoring and alerting modules</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions welcome! Open an issue or submit a PR.</p>"},{"location":"#license","title":"License","text":"<p>Distributed under the MIT License. See <code>LICENSE</code>.</p>"},{"location":"#contact","title":"Contact","text":"<ul> <li>LinkedIn</li> <li>Twitter/X</li> <li>seannjela@outlook.com</li> <li>About Me</li> </ul>"},{"location":"disclaimer/","title":"Disclaimer","text":"<p>The information and resources provided in this project are intended for educational and informational purposes only.</p>"},{"location":"disclaimer/#no-warranty","title":"No Warranty","text":"<p>This project is provided \"as is\" without warranty of any kind\u2014express or implied. While I have made every effort to ensure the accuracy and reliability of the information, I make no guarantees about:</p> <ul> <li>Suitability for any specific purpose  </li> <li>Completeness or accuracy of configurations or scripts  </li> <li>Security of infrastructure or deployments  </li> </ul> <p>Use at your own risk.</p>"},{"location":"disclaimer/#for-personal-use-learning","title":"For Personal Use / Learning","text":"<p>This project is part of a personal portfolio and is primarily intended to:</p> <ul> <li>Demonstrate practical implementation of technical concepts  </li> <li>Serve as a sandbox for experimentation  </li> <li>Be a reference for future personal or professional projects  </li> </ul> <p>It is not intended for production use without proper review and adaptation.</p>"},{"location":"disclaimer/#security-and-sensitive-data","title":"Security and Sensitive Data","text":"<p>Do not reuse any credentials, tokens, secrets, or keys shown in this project. They are either fake, expired, or meant only for demonstration.</p> <p>Always handle secrets securely and follow best practices for secret management (e.g., environment variables, sealed secrets, vaults).</p>"},{"location":"disclaimer/#opinions-are-my-own","title":"Opinions Are My Own","text":"<p>All opinions, techniques, and practices shared here reflect my personal learning journey and are not affiliated with or endorsed by any employer, client, or organization.</p>"},{"location":"disclaimer/#license","title":"License","text":"<p>This project is licensed under the MIT, which permits reuse, modification, and distribution\u2014with proper attribution.</p>"},{"location":"disclaimer/#contact","title":"Contact","text":"<p>If you spot issues, risks, or have questions about how something works, feel free to reach out:</p> <ul> <li>seannjela@outlook.com</li> <li>GitHub Issues</li> </ul>"},{"location":"0-quickstart/0-prerequisites/","title":"Prerequisites","text":"<p>This project uses Devbox to manage the development environment. Devbox provides a consistent, isolated environment with all the necessary CLI tools pre-installed.</p>"},{"location":"0-quickstart/0-prerequisites/#docker","title":"Docker","text":"<ul> <li>Follow the installation instructions for your operating system.</li> </ul> <p>The rest of the tools are already installed in the devbox environment</p>"},{"location":"0-quickstart/0-prerequisites/#devbox","title":"Devbox","text":"<ul> <li>Follow the installation instructions for your operating system.</li> </ul>"},{"location":"0-quickstart/0-prerequisites/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/your-username/your-repo.git\ncd your-repo\n</code></pre>"},{"location":"0-quickstart/0-prerequisites/#start-the-devbox-environment-and-poetry-environment","title":"Start the Devbox Environment and poetry environment","text":"<pre><code>devbox shell # Start the devbox environment (this will also start the poetry environment)\npoetry install # Install dependencies\npoetry env activate # use the output to activate the poetry environment ( ONLY IF DEVBOX DOES NOT ACTIVATE THE ENVIRONMENT)\n</code></pre> <p>Note</p> <p>The first time you run <code>devbox shell</code>, it will take a few minutes to install the necessary tools. But after that it will be much faster.</p>"},{"location":"0-quickstart/1-getting-started/","title":"Getting Started","text":"<p>Welcome! This section will walk you through how to get the project up and running on your local machine or development environment.</p>"},{"location":"0-quickstart/1-getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed all the requirements. See the Prerequisites section for detailed instructions on installing these tools.</p>"},{"location":"0-quickstart/1-getting-started/#walkthrough","title":"Walkthrough","text":"<p>After everything is wired up, you can run the following commands:</p> <pre><code>task setup\n\ntask status # check if everything is running\n\n# GIVE EVERYTHING A MINUTE TO SETUP THEN\ntask dev\n</code></pre> <p>This will start the devbox environment and poetry environment and install all dependencies. And that is all you need to do to get started. (Yes, really.)</p> <p>In a seperate terminal, run:</p> <pre><code># Option 1\ntask docs\n\n# Or if you prefer the docker version:\n# Option 2\ntask docs-docker\n\n# ONLY RUN ONE OF THE ABOVE\n</code></pre> <p>Docs are then available at: http://127.0.0.1:8030/</p> <p>All other commands are in the form of tasks. The project task file is <code>Taskfile.yaml</code>.</p> <pre><code>task --list-all # to see all project tasks\ntask &lt;command&gt; # usage\n</code></pre> <p>The project also uses gitflow for version control with gh-pages deployment automation. This is optional but you can also automate it using the <code>Taskfile.gitflow.yaml</code> file.</p> <pre><code>task -t Taskfile.gitflow.yaml --list-all # to see all gitflow tasks\ntask -t Taskfile.gitflow.yaml &lt;command&gt; # usage\n</code></pre> <p>See the Tasks section for more information on all tasks.</p>"},{"location":"0-quickstart/1-getting-started/#cleanup","title":"Cleanup","text":"<p>To tear everything down after testing:</p> <pre><code>task cleanup-dev # to cleanup everything running locally\ntask cleanup-prod # to cleanup everything running in production (IF YOU USED ANY PROD. WORKFLOWS)\ntask cleanup-all # to cleanup everything (local and production)\n</code></pre>"},{"location":"0-quickstart/1-getting-started/#need-help","title":"Need Help?","text":"<p>If you get stuck:</p> <ul> <li>Check the Troubleshooting guide.</li> <li>Open an issue on GitHub</li> </ul> <p>Happy building!</p>"},{"location":"1-architecture/0-overview/","title":"System Architecture Overview","text":"<p>This section provides a high-level overview of the architecture and design decisions behind the project. It outlines the system's core components, their responsibilities, and how they interact.</p>"},{"location":"1-architecture/0-overview/#design-philosophy","title":"Design Philosophy","text":"<p>Summarise your approach or values. Examples:</p> <ul> <li>Modular and composable</li> <li>Secure by default</li> <li>Automation-first (e.g., IaC, CI/CD)</li> <li>Portable/local-dev friendly</li> </ul>"},{"location":"1-architecture/0-overview/#core-components","title":"Core Components","text":""},{"location":"1-architecture/0-overview/#1-infrastructure","title":"1. Infrastructure","text":"<ul> <li>Describe how infrastructure is provisioned (e.g., Terraform, Pulumi)</li> <li>Where it's deployed (e.g., local Kind cluster, cloud, etc.)</li> <li>Example:</li> <li>Kind cluster created via <code>task dev</code></li> <li>Terraform used to manage Argo CD and related resources</li> </ul>"},{"location":"1-architecture/0-overview/#2-cicd","title":"2. CI/CD","text":"<ul> <li>What tools handle deployment?</li> <li>Example:</li> <li>Argo CD handles Kubernetes app delivery using the App of Apps pattern</li> <li>Image updates via argocd-image-updater</li> <li>Optional notification layer (e.g., Slack integration)</li> </ul>"},{"location":"1-architecture/0-overview/#3-secrets-configuration","title":"3. Secrets &amp; Configuration","text":"<ul> <li>Mention secret handling (e.g., Sealed Secrets, SOPS, Vault)</li> <li>Config management tools (e.g., Helm, Kustomize)</li> </ul>"},{"location":"1-architecture/0-overview/#architecture-diagram","title":"Architecture Diagram","text":"<p>Add a visual overview of your system if available.</p> <p></p> <p>If not available yet, note:</p> <p>Architecture diagram to be added in a future update.</p>"},{"location":"1-architecture/0-overview/#data-control-flow","title":"Data / Control Flow","text":"<p>Explain the high-level lifecycle or data flow:</p> <ol> <li>User runs <code>task dev</code></li> <li>Terraform provisions resources</li> <li>Argo CD bootstraps itself and deploys other apps</li> <li>Image updater checks container registries and pushes updates</li> <li>Notifications triggered via webhook \u2192 Slack</li> </ol>"},{"location":"1-architecture/0-overview/#related-pages","title":"Related Pages","text":"<ul> <li>Quickstart: Getting Started</li> <li>Topics / Application Layer</li> <li>Taskfile Automation</li> </ul>"},{"location":"2-project/1-topic2/","title":"Project Topic 2","text":""},{"location":"2-project/2-topic3/","title":"Project Topic 3","text":""},{"location":"2-project/notes/","title":"General Notes before we begin","text":"<p>A DevOps infrastructure repository structure must balance clarity, modularity, and separation of concerns. Mixing everything in one repository usually leads to coupling, poor security boundaries, and scaling issues.</p>"},{"location":"2-project/notes/#general-principles","title":"General principles","text":"<ul> <li>Separate stateful tools (Terraform, Ansible) from stateless deployment descriptors (Helm, Argo CD).</li> <li>Keep repositories scoped to lifecycle stage and ownership.</li> <li>Keep application code repositories separate from infrastructure repositories.</li> <li>Avoid a single monolithic repository unless the team is small and the infrastructure surface area is trivial.</li> </ul>"},{"location":"2-project/notes/#terraform-repositories","title":"Terraform repositories","text":"<p>Content:</p> <ul> <li>Providers and backend configuration (e.g. remote state, workspaces).</li> <li>Environment directories (<code>prod</code>, <code>staging</code>, <code>dev</code>) with their own variable files and state separation.</li> <li>Reusable modules in <code>modules/</code> with versioning.</li> <li>Global networking, IAM, and foundational infrastructure separate from application-level infrastructure.</li> </ul> <p>Best practice:</p> <ul> <li>One repository for foundational infrastructure (networking, IAM, shared services).</li> <li>One repository per domain/application if isolation and blast radius matter.</li> <li>Versioned modules, consumed via Git tags or a registry.</li> </ul> <p>Risks of one repository for all:</p> <ul> <li>Large blast radius if someone breaks main.</li> <li>Hard to isolate environments or delegate ownership.</li> <li>Longer CI/CD runs.</li> </ul>"},{"location":"2-project/notes/#helm-repositories","title":"Helm repositories","text":"<p>Content:</p> <ul> <li>Chart definitions for applications.</li> <li>Chart values files for each environment.</li> <li>A Helm chart repository (packaged charts hosted in an artifact registry, e.g. OCI or S3/GCS, not GitHub alone).</li> </ul> <p>Best practice:</p> <ul> <li>Keep Helm charts separate from Terraform.</li> <li>Each application may have its chart in its own repository, or a central \"charts repo\" if teams are small.</li> <li>Push packaged charts to a chart registry, not Git.</li> </ul>"},{"location":"2-project/notes/#argo-cd-repositories","title":"Argo CD repositories","text":"<p>Argo CD follows a GitOps model. It expects \"application repositories\" containing Kubernetes manifests or Helm chart references.</p> <p>Content:</p> <ul> <li><code>Application</code> CRDs declaring desired state.</li> <li>Environment overlays (e.g. <code>kustomize</code> overlays or Helm values).</li> <li>References to Helm chart repositories.</li> </ul> <p>Best practice:</p> <ul> <li>Separate GitOps config repo(s) from app code repos.</li> <li>One \"Argo CD apps of apps\" repo for cluster bootstrapping.</li> <li>Each environment can have its own repo if desired.</li> </ul>"},{"location":"2-project/notes/#ansible-repositories","title":"Ansible repositories","text":"<p>Content:</p> <ul> <li>Inventories (grouped by environment).</li> <li>Roles with idempotent tasks.</li> <li>Playbooks referencing roles.</li> <li>Group and host vars.</li> </ul> <p>Best practice:</p> <ul> <li>Keep Ansible in its own repository, especially if used for configuration management outside Kubernetes (VMs, bare metal, hybrid).</li> <li>If Ansible is only used as a helper (e.g. bootstrap EC2 before Terraform takes over), it can live with Terraform in a \"provisioning\" repo.</li> </ul>"},{"location":"2-project/notes/#recommended-separation","title":"Recommended separation","text":"<ul> <li>Terraform repo(s): infrastructure provisioning (cloud resources).</li> <li>Helm repo(s): application packaging.</li> <li>Argo CD repo(s): GitOps manifests and environment overlays.</li> <li>Ansible repo(s): configuration management.</li> <li>Application repos: contain only application code and CI/CD pipelines.</li> </ul>"},{"location":"2-project/notes/#practical-models","title":"Practical models","text":"<ol> <li> <p>Small team, low complexity:</p> </li> <li> <p>One infrastructure mono-repo containing Terraform, Helm charts, and Argo CD configs in separate folders.</p> </li> <li>Clear folder boundaries, strict CI jobs for each tool.</li> <li> <p>Only feasible with low headcount and strict discipline.</p> </li> <li> <p>Medium/large team, growing infra:</p> </li> <li> <p>Separate repositories per tool and purpose.</p> </li> <li>Terraform foundational infra repo + domain infra repos.</li> <li>Helm charts repo or per-app repo.</li> <li>Argo CD GitOps config repo.</li> <li>Ansible repo (if needed).</li> </ol>"},{"location":"2-project/notes/#notes-on-atlantis-for-terraform","title":"Notes on Atlantis for Terraform","text":"<p>Atlantis is an automation tool that runs Terraform plans and applies through pull requests. It enables safe collaboration and GitOps-style workflows for infrastructure.</p> <p>Core concepts:</p> <ul> <li>Atlantis runs as a service in Kubernetes or on a VM.</li> <li>It listens for GitHub/GitLab/Bitbucket pull request webhooks.</li> <li>Workflow: Developer opens PR \u2192 Atlantis runs <code>terraform plan</code> \u2192 Reviewer sees plan \u2192 After approval, Atlantis runs <code>terraform apply</code>.</li> <li>All Terraform state backends must be remote (S3 + DynamoDB, GCS + locking, etc.). Atlantis does not store state.</li> <li>Configuration is managed in <code>atlantis.yaml</code> or <code>repos.yaml</code>.</li> </ul> <p>Best practices:</p> <ul> <li>Run Atlantis inside Kubernetes with RBAC, network policies, and TLS.</li> <li>Do not give Atlantis direct cloud credentials; use IAM roles or workload identity.</li> <li>Use <code>atlantis.yaml</code> to define workflows per repo (e.g. different workspaces or modules).</li> <li>Enforce branch protections so only Atlantis can apply.</li> <li>Store Atlantis logs centrally for audit.</li> </ul>"},{"location":"2-project/notes/#how-it-works","title":"How It Works","text":"<ol> <li>Developer creates a PR with Terraform code.</li> <li> <p>Atlantis detects the PR and posts a comment like:</p> <pre><code># Atlantis commands can be run by commenting below:\n- atlantis plan\n- atlantis apply\n</code></pre> </li> <li> <p>Developer comments on the PR:</p> <pre><code>atlantis plan\n</code></pre> </li> <li> <p>Atlantis runs <code>terraform plan</code>, shows the output in the PR.</p> </li> <li> <p>If all looks good, developer comments:</p> <p><pre><code>atlantis apply\n</code></pre> 6. Atlantis applies the changes to the actual cloud infra.</p> </li> </ol>"},{"location":"2-project/notes/#pre-commit-hooks-validate-before-push","title":"Pre-commit Hooks: Validate Before Push","text":""},{"location":"2-project/notes/#what-is-a-pre-commit-hook","title":"What is a Pre-commit Hook?","text":"<p>A pre-commit hook is a small script that runs before you make a Git commit. It catches issues early, before bad code gets committed or pushed.</p>"},{"location":"2-project/notes/#use-with-terraform","title":"\ud83d\udc77 Use with Terraform","text":"<p>With Terraform, pre-commit hooks are often used to:</p> <ul> <li>Format code with <code>terraform fmt</code></li> <li>Validate syntax with <code>terraform validate</code></li> <li>Run security checks with <code>tflint</code>, <code>tfsec</code>, or <code>checkov</code></li> <li>Enforce best practices (like locking provider versions)</li> </ul>"},{"location":"2-project/notes/#how-to-set-it-up","title":"\ud83d\udd27 How To Set It Up","text":"<ol> <li>Install pre-commit:</li> </ol> <pre><code>pip install pre-commit\n</code></pre> <p>2 Create a <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.77.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_tflint\n</code></pre> <p>Developer workflow (local):</p> <pre><code>pre-commit install\npre-commit run               # runs fmt, validate, tflint on changed files\n</code></pre> <p>CI workflow (strict checks):</p> <pre><code>pre-commit run --all-files --hook-stage manual\n</code></pre> <p>Now every time you run <code>git commit</code>, it will: - Auto-format your <code>.tf</code> files - Check syntax and linting - Block commits if anything fails</p>"},{"location":"2-project/notes/#core-aws-services","title":"Core AWS Services","text":"<p>There are services that get used in AWS. We will mainly focus on these as these cover teh majority of use cases in the cloud.</p> <ul> <li> <p>VPC (Virtual Private Cloud): Creates a private network in the cloud, like a secure bubble for your servers and data, separate from the public internet.</p> </li> <li> <p>ALB (Application Load Balancer): Spreads incoming traffic across multiple servers to keep things running smoothly and avoid overload.</p> </li> <li> <p>Route53: Manages domain names (like www.yoursite.com) and directs internet traffic to the right place.</p> </li> <li> <p>EC2 (Elastic Compute Cloud): Provides virtual servers you can rent to run apps or store data, with options to scale up or down.</p> </li> <li> <p>ECS (Elastic Container Service): Helps manage and run Docker containers (lightweight app packages) on AWS, great for simpler setups.</p> </li> <li> <p>EKS (Elastic Kubernetes Service): Manages Kubernetes, a system for running and scaling containerized apps, ideal for complex setups.</p> </li> <li> <p>Lambda: Runs code without needing a server, automatically scaling based on demand  (serverless computing).</p> </li> <li> <p>S3 (Simple Storage Service): Offers unlimited online storage for files like photos or backups, accessible anywhere.</p> </li> <li> <p>RDS (Relational Database Service): Manages databases (like MySQL or PostgreSQL) for storing and organizing data, with easy setup.</p> </li> <li> <p>CloudWatch: Monitors your AWS resources, tracks performance, and sends alerts if something goes wrong.</p> </li> <li> <p>IAM (Identity and Access Management): Controls who can access your AWS services and what they can do, like a security guard.</p> </li> <li> <p>Fargate: Runs containers without managing servers, simplifying container use with automatic scaling.</p> </li> <li> <p>EBS (Elastic Block Store): Provides persistent storage for EC2 instances, like a hard drive that stays even if the server restarts.</p> </li> <li> <p>ECR (Elastic Container Registry): A place to store and manage your Docker container images securely.</p> </li> <li> <p>DynamoDB: A fast, flexible database for storing data in a table format, great for apps needing quick access.</p> </li> </ul>"},{"location":"2-project/notes/#ecs-vs-eks-vs-serverless","title":"ECS vs EKS vs Serverless","text":""},{"location":"2-project/notes/#serverless-functions-aws-lambda","title":"Serverless Functions (AWS Lambda)","text":"<ul> <li>Model: Event-driven functions. Upload code, AWS runs it.</li> <li>Use cases: APIs, glue code, event processing, cron jobs, IoT.</li> <li>Scaling: Instant per-invocation scaling.</li> <li>Control: No OS access, no container management.</li> <li>Limits: 15-minute max runtime, memory \u2264 10 GB, ephemeral filesystem only.</li> <li>Cost: Pay per request and execution time (ms).</li> <li>Trade-offs: Cold starts, runtime limits, vendor lock-in, no long-lived processes.</li> </ul>"},{"location":"2-project/notes/#serverless-containers-ecseks-with-fargate","title":"Serverless Containers (ECS/EKS with Fargate)","text":"<ul> <li>Model: User provides container image. AWS provisions compute.</li> <li>Use cases: Microservices, APIs, batch jobs, workers, containers that need &gt;15 min runtime.</li> <li>Scaling: Per-task/pod automatic scaling.</li> <li>Control: Control over container runtime, but no host-level access.</li> <li>Limits: Only supported CPU/memory sizes, no privileged mode.</li> <li>Cost: Pay per vCPU-second and GB-second allocated.</li> <li>Trade-offs: More expensive than EC2 at scale, slower startup, less flexibility.</li> </ul>"},{"location":"2-project/notes/#managed-containers-ecseks-on-ec2","title":"Managed Containers (ECS/EKS on EC2)","text":"<ul> <li>Model: User runs container clusters on EC2. AWS provides orchestration (ECS) or Kubernetes (EKS).</li> <li>Use cases: Long-running services, GPU/ML workloads, custom networking, legacy apps.</li> <li>Scaling: User-managed with Auto Scaling Groups (EC2) + orchestrator scaling rules.</li> <li>Control: Full control of EC2 host, networking, daemon processes.</li> <li>Limits: Need to patch, scale, and manage hosts.</li> <li>Cost: Cheaper per unit compute for stable workloads.</li> <li>Trade-offs: Higher ops burden.</li> </ul>"},{"location":"2-project/notes/#virtual-machines-raw-ec2","title":"Virtual Machines (Raw EC2)","text":"<ul> <li>Model: User provisions VMs directly. Full OS control.</li> <li>Use cases: Legacy workloads, custom runtimes, monoliths, databases, stateful apps.</li> <li>Scaling: Manual or via autoscaling groups.</li> <li>Control: Complete, down to kernel and drivers.</li> <li>Limits: Must manage everything (OS patching, monitoring, scaling, failures).</li> <li>Cost: Pay for provisioned instance time, idle or not.</li> <li>Trade-offs: High operational overhead.</li> </ul>"},{"location":"2-project/notes/#summary","title":"Summary","text":"<ul> <li>Lambda: Small, event-driven code. Fastest to ship. Hard runtime limits.</li> <li>Fargate (ECS/EKS): Container workloads without servers. Simplified ops. Costlier per unit.</li> <li>ECS/EKS on EC2: Container workloads with host control. Best balance for steady workloads.</li> <li>EC2: Full control. Most flexible. Heaviest ops burden.</li> </ul>"},{"location":"2-project/setup/","title":"Setup","text":"<p>The effective folder structure:</p> <pre><code>.\n\u251c\u2500\u2500 terraform/\n\u2502   \u2514\u2500\u2500 envs/                     # Environment-specific configurations\n\u2502       \u251c\u2500\u2500 dev/\n\u2502       \u2502   \u251c\u2500\u2500 main.tf           # Calls upstream modules (VPC, RDS, ECS, etc.)\n\u2502       \u2502   \u251c\u2500\u2500 backend.tf        # Remote backend config (state isolation)\n\u2502       \u2502   \u251c\u2500\u2500 variables.tf      # Variable definitions for this env\n\u2502       \u2502   \u251c\u2500\u2500 providers.tf      # Provider config (AWS,GCP,AZURE) per env\n\u2502       \u2502   \u2514\u2500\u2500 dev.tfvars        # Only immutable, non-sensitive defaults\n\u2502       \u251c\u2500\u2500 staging/              # Mirrors dev; used for integration tests\n\u2502       \u2514\u2500\u2500 prod/                 # Mirrors staging; stricter quotas and policies\n\u2502\n\u251c\u2500\u2500 versions.tf               # Locks Terraform &amp; provider versions\n\u251c\u2500\u2500 .tflint.hcl               # Linting rules\n\u251c\u2500\u2500 .checkov.yml              # Static security analysis rules\n\u251c\u2500\u2500 .infracost.yml            # Cost estimation config\n\u251c\u2500\u2500 .pre-commit-config.yaml   # Developer hygiene hooks\n\u251c\u2500\u2500 .trivyignore              # Ignore rules for container scans\n\u2514\u2500\u2500 README.md                 # Explains repo usage and structure\n</code></pre>"},{"location":"2-project/setup/#2-modules-in-practice","title":"2. Modules in practice","text":""},{"location":"2-project/setup/#21-direct-call-pattern-envsprodmaintf-abridged","title":"2.1 Direct call pattern (<code>envs/prod/main.tf</code> abridged)","text":"<pre><code># VPC\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"  # Official module\n  version = \"~&gt; 6.0\"                          # Pin MAJOR, allow patch/minor upgrades\n  name    = \"${var.service}-vpc\"\n  cidr    = var.cidr_block\n\n  # Take first 3 AZs to spread resources\n  azs     = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  public_subnets  = var.public_subnets\n  private_subnets = var.private_subnets\n\n  enable_nat_gateway = true\n  tags = local.tags\n}\n\n# RDS\nmodule \"db\" {\n  source  = \"terraform-aws-modules/rds/aws\"\n  version = \"~&gt; 6.12\"\n  identifier = \"${var.service}-db\"\n\n  engine         = \"postgres\"\n  engine_version = \"16.2\"\n  instance_class = \"db.t4g.medium\"\n  subnet_ids     = module.vpc.private_subnets\n  multi_az       = true                     # Highly available\n  backup_retention_period = 7\n  deletion_protection     = true            # Safety guard\n\n  username = var.db_user\n  password = data.aws_secretsmanager_secret_version.db_pwd.secret_string\n  tags     = local.tags\n}\n\n# ECS\nmodule \"ecs\" {\n  source  = \"terraform-aws-modules/ecs/aws\"\n  version = \"~&gt; 5.13\"\n  cluster_name   = \"${var.service}-${var.environment}\"\n  capacity_providers = [\"FARGATE\", \"FARGATE_SPOT\"]\n\n  services = {\n    web = {\n      cpu    = 512\n      memory = 1024\n      desired_count = 2\n\n      # Container definition encoded as JSON\n      container_definitions = jsonencode([{\n        name  = \"web\"\n        image = \"${var.image}@${var.image_digest}\"\n\n        portMappings = [{ containerPort = 8080 }]\n\n        secrets = [\n          { name = \"DB_URL\", valueFrom = module.db.secret_arn }\n        ]\n\n        environment = [\n          { name = \"SPRING_PROFILES_ACTIVE\", value = var.environment }\n        ]\n      }])\n\n      load_balancer = {\n        target_group_arn = module.ecs.alb_target_group_arns[\"web\"]\n      }\n    }\n  }\n  tags = local.tags\n}\n</code></pre> <p>Rationale:</p> <ul> <li>Call upstream modules directly and pin versions.</li> <li>Inject secrets via ARN, never plaintext</li> <li>Use locals for tagging consistency.</li> </ul> <p>Rule of thumb: wrap if you need mandatory tags or guard-rails; never fork \u2013 you\u2019ll lose the upstream upgrades. </p>"},{"location":"2-project/setup/#3-remote-backend-recipes","title":"3. Remote backend recipes","text":""},{"location":"2-project/setup/#terraform-cloud-simplest","title":"Terraform Cloud (simplest)","text":"<pre><code>terraform {\n  backend \"remote\" {\n    organization = \"acme-solo\"\n    workspaces { name = \"webapp-prod\" }\n  }\n}\n</code></pre> <p>Pros: simplest setup, state encryption managed. Cons: paid tier may be needed for policies.</p>"},{"location":"2-project/setup/#s3-dynamodb-fully-oss","title":"S3 + DynamoDB (fully OSS)","text":"<p><pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"acme-terraform-state\" # must exist beforehand\n    key            = \"prod/terraform.tfstate\"\n    region         = \"eu-central-1\"\n    dynamodb_table = \"terraform-locks\"      # provides locking\n    encrypt        = true                   # SSE-KMS recommended\n  }\n}\n</code></pre> Create the bucket/table once manually or via an isolated bootstrap stack. Pros: fully OSS, no SaaS dependency. Cons: requires manual bootstrap of bucket + table.</p>"},{"location":"2-project/setup/#4-versionstf","title":"4. <code>versions.tf</code>","text":"<pre><code>terraform {\n  required_version = \"~&gt; 1.9\"         # June 2025 LTS\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 6.0\"\n    }\n  }\n}\n</code></pre> <p>Commit the generated <code>terraform.lock.hcl</code> so CI is deterministic.</p>"},{"location":"2-project/setup/#5-security-defaults","title":"5. Security defaults","text":"Layer Setting IAM GitHub OIDC \u21d2 short-lived role; no static keys on laptops State SSE-KMS on S3 / workspace-level encryption on TF Cloud Transit TLS 1.2+ only (<code>aws_lb_listener</code> default) Data RDS storage + backups encrypted \u2022 automatic minor-version upgrades Secrets Stored in AWS Secrets Manager; injected by ARN, never in plain vars Static analysis Pre-commit hook: <code>terraform fmt \u2192 tflint \u2192 tfsec \u2192 checkov</code> Policy as code Sentinel / OPA rules (e.g. deny public S3) \u2013 add when compliance rises"},{"location":"2-project/setup/#6-github-actions-pipeline-githubworkflowsterraformyml","title":"6. GitHub Actions pipeline (<code>.github/workflows/terraform.yml</code>)","text":"<p><pre><code>name: Terraform\n\non:\n  pull_request:\n    paths: [\"terraform/**\"]\n\npermissions: { id-token: write, contents: read }\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: hashicorp/setup-terraform@v3\n      - run: terraform fmt -check -recursive\n      - run: terraform init -backend-config=\"envs/${{ github.head_ref }}/backend.hcl\"\n      - run: terraform validate\n\n  plan:\n    needs: validate\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: hashicorp/setup-terraform@v3\n      - run: terraform init -backend-config=\"envs/${{ github.head_ref }}/backend.hcl\"\n      - run: terraform plan -out=tfplan\n      - uses: actions/upload-artifact@v4\n        with: { name: tfplan, path: tfplan }\n\n  apply:\n    if: github.event.pull_request.merged == true\n    environment: prod        # requires manual approval gate\n    needs: plan\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: hashicorp/setup-terraform@v3\n      - run: terraform init -backend-config=\"envs/prod/backend.hcl\"\n      - run: terraform apply -auto-approve tfplan\n</code></pre> Design notes:</p> <ul> <li>OIDC \u2192 AWS role assumption. No long-lived keys.</li> <li>Manual approval enforced by GitHub environments.</li> <li>Plans are generated on PR, applied only after merge.</li> </ul>"},{"location":"2-project/setup/#7-local-developer-ergonomics","title":"7. Local developer ergonomics","text":"<ul> <li><code>make deploy ENV=dev</code> \u2013 wraps <code>terraform init</code>/<code>plan</code>/<code>apply</code>.</li> <li>Direnv \u2013 autoloads environment variables (<code>AWS_PROFILE</code>, region).</li> <li>.pre-commit-config.yaml \u2013 keeps style &amp; security on every commit:</li> </ul> <pre><code>repos:\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.79.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: tflint\n      - id: tfsec\n      - id: checkov\n</code></pre>"},{"location":"2-project/setup/#8-cost-drift-guard-rails","title":"8. Cost &amp; drift guard-rails","text":"Tool Schedule Action Infracost On every PR Shows monthly delta in comment <code>terraform plan</code> Nightly GitHub Action Exit code 2 \u21d2 Slack/Email alert AWS Budgets 80 % of monthly limit Sends SNS \u2192 Slack"},{"location":"2-project/setup/#9-scaling-failure-proofing-checklist","title":"9. Scaling &amp; failure-proofing checklist","text":"<p>[] Multi-AZ: ALBs, RDS, subnets across \u2265 2 AZs.</p> <p>[] Auto-scaling: ECS services with Fargate Spot + CPU/latency metrics.</p> <p>[] Backups: RDS retention 7 days, cross-region snapshot copy.</p> <p>[] Observability: CloudWatch dashboards/alarms. Add Prometheus/Grafana if needed.</p> <p>[] Deployments: ECS rolling updates. Optionally add CodeDeploy for blue-green.</p>"},{"location":"2-project/setup/#10-upgrade-workflow","title":"10. Upgrade workflow","text":"<ul> <li> <p>Review release notes of each module.</p> </li> <li> <p>Bump version pin in branch.</p> </li> <li> <p>Run terraform init -upgrade in dev.</p> </li> <li> <p>Validate plan.</p> </li> <li> <p>Merge \u2192 pipeline applies to staging and prod with gate.</p> </li> </ul> <p>(You usually only do this quarterly; the community publishes clear guides.)</p>"},{"location":"2-project/setup/#11-when-this-template-stops-being-enough","title":"11. When this template stops being enough","text":"Scenario Next step Multiple squads or &gt; 3 prod environments Introduce Terragrunt or a platform (Spacelift/Scalr) for DRY-er roots Heavy compliance (PCI/HIPAA, audit trails) Add OPA/Sentinel CI gates, Service Control Policies, AWS Control Tower Multi-cloud or edge workloads Look at CDK for Terraform or Crossplane to abstract vendors"},{"location":"2-project/setup/#tldr-printable-checklist","title":"TL;DR printable checklist","text":"<ul> <li> One mono-repo with <code>envs/</code> for each environment</li> <li> Remote state secured &amp; versioned</li> <li> Use <code>terraform-aws-modules/*</code> directly, pinned to major versions</li> <li> OIDC \u2192 no static AWS keys</li> <li> Pre-commit: fmt, validate, tflint, tfsec, checkov</li> <li> GitHub Actions plan on PR, apply on merge with manual prod gate</li> <li> Encrypt &amp; tag everything; secrets via Secrets Manager</li> <li> Nightly drift plan + Infracost + Budget alerts</li> </ul>"},{"location":"2-project/setup/#using-the-template-in-devprod","title":"Using the Template in dev/prod","text":"<p>Each environment is isolated in its own directory under <code>envs/</code>. You always <code>cd</code> into that environment\u2019s directory before running Terraform. This ensures state, variables, and backends remain separate.</p>"},{"location":"2-project/setup/#1-backend-configuration","title":"1. Backend configuration","text":""},{"location":"2-project/setup/#envsdevbackendtf","title":"<code>envs/dev/backend.tf</code>","text":"<pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"acme-terraform-state\"\n    key            = \"dev/terraform.tfstate\"  # path unique to dev\n    region         = \"eu-central-1\"\n    dynamodb_table = \"terraform-locks\"\n    encrypt        = true\n  }\n}\n</code></pre>"},{"location":"2-project/setup/#envsprodbackendtf","title":"<code>envs/prod/backend.tf</code>","text":"<pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"acme-terraform-state\"\n    key            = \"prod/terraform.tfstate\" # path unique to prod\n    region         = \"eu-central-1\"\n    dynamodb_table = \"terraform-locks\"\n    encrypt        = true\n  }\n}\n</code></pre>"},{"location":"2-project/setup/#2-main-module-calls","title":"2. Main module calls","text":"<p>Both <code>main.tf</code> files are structurally the same. They call upstream modules but parameterise with environment-specific variables.</p>"},{"location":"2-project/setup/#envsdevmaintf","title":"<code>envs/dev/main.tf</code>","text":"<pre><code>module \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~&gt; 6.0\"\n\n  name    = \"dev-vpc\"\n  cidr    = var.cidr_block\n  azs     = slice(data.aws_availability_zones.available.names, 0, 2)\n\n  public_subnets  = var.public_subnets\n  private_subnets = var.private_subnets\n\n  enable_nat_gateway = false   # cheaper for dev\n  tags = local.tags\n}\n</code></pre>"},{"location":"2-project/setup/#envsprodmaintf","title":"<code>envs/prod/main.tf</code>","text":"<pre><code>module \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~&gt; 6.0\"\n\n  name    = \"prod-vpc\"\n  cidr    = var.cidr_block\n  azs     = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  public_subnets  = var.public_subnets\n  private_subnets = var.private_subnets\n\n  enable_nat_gateway = true    # HA and scaling for prod\n  tags = local.tags\n}\n</code></pre>"},{"location":"2-project/setup/#3-variables","title":"3. Variables","text":""},{"location":"2-project/setup/#envsdevdevtfvars","title":"<code>envs/dev/dev.tfvars</code>","text":"<pre><code>service        = \"webapp\"\nenvironment    = \"dev\"\ncidr_block     = \"10.0.0.0/16\"\npublic_subnets = [\"10.0.1.0/24\"]\nprivate_subnets= [\"10.0.101.0/24\"]\ndb_user        = \"devuser\"\n</code></pre>"},{"location":"2-project/setup/#envsprodprodtfvars","title":"<code>envs/prod/prod.tfvars</code>","text":"<pre><code>service        = \"webapp\"\nenvironment    = \"prod\"\ncidr_block     = \"10.1.0.0/16\"\npublic_subnets = [\"10.1.1.0/24\", \"10.1.2.0/24\", \"10.1.3.0/24\"]\nprivate_subnets= [\"10.1.101.0/24\", \"10.1.102.0/24\", \"10.1.103.0/24\"]\ndb_user        = \"produser\"\n</code></pre> <p>Secrets (passwords, keys) must not be stored in <code>*.tfvars</code>. Use Secrets Manager or SSM.</p>"},{"location":"2-project/setup/#4-commands","title":"4. Commands","text":""},{"location":"2-project/setup/#for-development","title":"For development","text":"<pre><code>cd envs/dev\nterraform init\nterraform plan -var-file=dev.tfvars\nterraform apply -var-file=dev.tfvars\n</code></pre>"},{"location":"2-project/setup/#for-production","title":"For production","text":"<pre><code>cd envs/prod\nterraform init\nterraform plan -var-file=prod.tfvars\nterraform apply -var-file=prod.tfvars\n</code></pre>"},{"location":"2-project/setup/#key-notes","title":"Key notes","text":"<ul> <li>Each <code>backend.tf</code> ensures state isolation per environment.</li> <li>Each <code>*.tfvars</code> file holds only immutable config (CIDRs, naming, sizes), never secrets.</li> <li>Resource behaviour differs per environment (e.g. NAT disabled in dev, enabled in prod).</li> <li>CI/CD can switch <code>cd envs/&lt;env&gt;</code> based on branch or workflow input.</li> </ul>"},{"location":"2-project/setup/#secrets","title":"Secrets","text":"<p>Secrets are never checked into the repo. Terraform only references them at runtime from a managed secret store. Provisioning works by:</p>"},{"location":"2-project/setup/#1-store-the-secret","title":"1. Store the secret","text":""},{"location":"2-project/setup/#example-database-password-in-aws-secrets-manager","title":"Example: database password in AWS Secrets Manager","text":"<pre><code>aws secretsmanager create-secret \\\n  --name db/webapp/prod/password \\\n  --secret-string 'SuperStrongPassword123!'\n</code></pre> <p>or for SSM Parameter Store (encrypted with KMS):</p> <pre><code>aws ssm put-parameter \\\n  --name /db/webapp/prod/password \\\n  --value 'SuperStrongPassword123!' \\\n  --type SecureString\n</code></pre>"},{"location":"2-project/setup/#2-reference-secret-in-terraform","title":"2. Reference secret in Terraform","text":""},{"location":"2-project/setup/#using-secrets-manager","title":"Using Secrets Manager","text":"<pre><code># Fetch the latest version of the secret\ndata \"aws_secretsmanager_secret_version\" \"db_pwd\" {\n  secret_id = \"db/webapp/${var.environment}/password\"\n}\n\nmodule \"db\" {\n  source  = \"terraform-aws-modules/rds/aws\"\n  version = \"~&gt; 6.12\"\n\n  identifier             = \"${var.service}-db\"\n  engine                 = \"postgres\"\n  username               = var.db_user\n  password               = data.aws_secretsmanager_secret_version.db_pwd.secret_string\n  # other RDS inputs...\n}\n</code></pre>"},{"location":"2-project/setup/#using-ssm-parameter-store","title":"Using SSM Parameter Store","text":"<pre><code>data \"aws_ssm_parameter\" \"db_pwd\" {\n  name = \"/db/webapp/${var.environment}/password\"\n  with_decryption = true\n}\n\nmodule \"db\" {\n  source  = \"terraform-aws-modules/rds/aws\"\n  version = \"~&gt; 6.12\"\n\n  identifier = \"${var.service}-db\"\n  username   = var.db_user\n  password   = data.aws_ssm_parameter.db_pwd.value\n}\n</code></pre>"},{"location":"2-project/setup/#3-access-control","title":"3. Access control","text":"<ul> <li>Terraform execution role (from GitHub Actions OIDC or developer IAM role) must have read-only permission for that secret. Example IAM policy:</li> </ul> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"ssm:GetParameter\"\n      ],\n      \"Resource\": [\n        \"arn:aws:secretsmanager:eu-central-1:123456789012:secret:db/webapp/*\",\n        \"arn:aws:ssm:eu-central-1:123456789012:parameter/db/webapp/*\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"2-project/setup/#4-provisioning-flow","title":"4. Provisioning flow","text":"<ul> <li>Secrets created once manually or by a bootstrap script.</li> <li>Terraform plan/apply runs. It pulls the secret value dynamically from AWS.</li> <li>RDS or ECS module consumes it as input.</li> <li>The secret never enters Git history, <code>.tfvars</code>, or CI logs.</li> </ul>"},{"location":"2-project/setup/#5-runtime-injection-into-workloads","title":"5. Runtime injection into workloads","text":"<p>Example with ECS:</p> <pre><code>container_definitions = jsonencode([{\n  name  = \"web\"\n  image = var.image\n  secrets = [\n    { name = \"DB_PASSWORD\", valueFrom = data.aws_secretsmanager_secret.db_pwd.arn }\n  ]\n}])\n</code></pre> <p>ECS injects the secret into the container environment at runtime.</p>"},{"location":"2-project/setup/#recommended-cookie-cutter-starting-point","title":"Recommended \u201ccookie-cutter\u201d starting point","text":"<p>Pick \u2192 <code>terramate-io/terramate-quickstart-aws</code>.</p> <p>Among the public, maintained starters it is the only one that already folds in all the must-haves we listed earlier while still staying light enough for one engineer.</p> Built-in item Status in template Remote state (S3 + DynamoDB) Pre-wired OIDC GitHub \u2192 AWS Pre-wired CI/CD GitOps pipeline GitHub Actions plans \u2192 PR approval \u2192 auto-apply Drift detection Scheduled GitHub Action + Slack/PR comment Multi-env / multi-account <code>stg</code> + <code>prd</code> stacks out of the box Pre-commit (<code>tflint</code>, <code>tfsec</code>, <code>checkov</code>) Included Scaffolded VPC, NAT, LB, compute layer VPC + sample EKS; easy to swap to ECS/Lambda Change-detection orchestration Terramate change-sets (so plans only run where code changed) Terraform/OpenTofu compatible Yes"},{"location":"2-project/setup/#setting-things-up","title":"Setting Things up","text":"<p>The following is the reference arhitecture that we will be deploying with Terraform:</p> <p></p> <p>We First create an IAM user and configure the aws cli:</p> <pre><code>aws configure\n</code></pre> <p>We are using terraform cloud backend.</p> <p>We initialise the terraform backend by stating the <code>terraform {}</code> block in the <code>backend.tf</code>.</p> <p>Then we <code>terraform login</code> and create a token to be used on the cli.</p> <p>Since we are using Terraform Cloud:</p> <p>We use Terraform Cloud \u2192 AWS OIDC dynamic credentials. Steps:</p>"},{"location":"2-project/setup/#create-the-oidc-identity-provider-in-aws","title":"Create the OIDC identity provider in AWS","text":"<ol> <li>Open IAM \u2192 Identity providers \u2192 Add provider \u2192 OpenID Connect.</li> <li>Set Provider URL to <code>https://app.terraform.io</code> without trailing slash.</li> <li>Set Audience to <code>aws.workload.identity</code>.</li> <li>Save and note the provider ARN.</li> </ol>"},{"location":"2-project/setup/#create-the-iam-role-the-workspace-will-assume","title":"Create the IAM role the workspace will assume","text":"<ol> <li>Create a new role \u2192 Web identity \u2192 Select the OIDC provider you created.</li> <li>Workspace Run \u2192 this is the correct option for standard Terraform Cloud workspaces.3. Attach these permissions policy for the AWS resources Terraform must manage. (For prod attach stricter policies): </li> </ol> <p>This restricts the token to the exact organisation, project, and workspaces(dev, bootstrap, staging, prod =&gt; this is very importatnt). Use <code>run_phase =&gt; *</code> if one role is shared by plan and apply. Create two roles if plan and apply need different permissions and set <code>run_phase -&gt; plan</code> or <code>run_phase =&gt; apply</code>.</p> <p>example trusted entities entry:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Federated\": \"arn:aws:iam::xxxxx\"\n      },\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"app.terraform.io:aud\": \"aws.workload.identity\"\n        },\n        \"StringLike\": {\n          \"app.terraform.io:sub\": [\n            \"organization:devopssean:project:tf-demo:workspace:dev:run_phase:*\",\n            \"organization:devopssean:project:tf-demo:workspace:bootstrap:run_phase:*\",\n            \"organization:devopssean:project:tf-demo:workspace:prod:run_phase:*\",\n            \"organization:devopssean:project:tf-demo:workspace:staging:run_phase:*\"\n          ]\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"2-project/setup/#add-variables-in-the-terraform-cloud-workspace","title":"Add variables in the Terraform Cloud workspace","text":"<ol> <li> <p>In Workspace \u2192 Variables, add environment variables:</p> </li> <li> <p><code>TFC_AWS_PROVIDER_AUTH=true</code></p> </li> <li><code>TFC_AWS_RUN_ROLE_ARN=arn:aws:iam::...</code></li> <li>Optionally <code>AWS_REGION=&lt;region&gt;</code> if not set in the provider block.</li> <li>Optionally <code>TFC_AWS_PLAN_ROLE_ARN</code> and <code>TFC_AWS_APPLY_ROLE_ARN</code> if using separate roles.</li> <li>Use a Variable Set if multiple workspaces share the role.</li> </ol> <p>Warning</p> <p>DOUBLE CHECK AND TRIPPLE CHECK that the variables are of Category Environment and NOT terraform.</p>"},{"location":"2-project/setup/#keep-the-provider-block-minimal-in-each-environment","title":"Keep the provider block minimal in each environment","text":"<p><code>envs/dev/providers.tf</code>:</p> <pre><code>provider \"aws\" {\n  region = \"eu-central-1\"  # or omit and set AWS_REGION in workspace vars\n  default_tags {\n    tags = {\n      environment = \"dev\"\n      service     = var.service\n    }\n  }\n}\n</code></pre> <p>No access keys. No profiles. Terraform Cloud injects short-lived credentials at run time.</p>"},{"location":"2-project/setup/#run-the-workspace","title":"Run the workspace","text":"<ol> <li>Trigger a plan in Terraform Cloud.</li> <li>Confirm the run log shows dynamic credentials in use and no IMDS lookups.</li> <li>Apply after review.</li> </ol>"},{"location":"2-project/setup/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>\u201cNo valid credential sources found\u201d means the workspace variables are missing or the trust policy does not match the token. Fix the variables or the <code>sub</code> conditions.</p> </li> <li> <p>\u201cInvalid audience\u201d means the trust policy expects a different <code>aud</code>. Set <code>app.terraform.io:aud</code> to <code>aws.workload.identity</code> or match your custom audience.</p> </li> <li> <p>Access denied during plan or apply means the role\u2019s permissions policy is too narrow. Add the exact actions Terraform needs and re-plan.</p> </li> </ul>"},{"location":"2-project/setup/#security-notes","title":"Security notes","text":"<ul> <li> <p>Lock the trust policy to the specific organisation, project, and workspace to prevent cross-org token reuse.</p> </li> <li> <p>Prefer separate roles for plan and apply to enforce read-only during plan if required.</p> </li> <li> <p>Use IAM Access Analyzer to validate the trust policy.</p> </li> <li> <p>Avoid static keys in Terraform Cloud entirely.</p> </li> </ul> <p>We then apply the configuration in the <code>terraform/envs/dev</code> folder:</p> <pre><code>task tf-apply-dev\n</code></pre> <p>We then check what was provisioned in Terraform Cloud:</p> <p></p> <p>We then destroy the infrastructure:</p> <pre><code>task tf-destroy-dev\n</code></pre> <p>Info</p> <p>To select an AMI whilst using a ac2_instance module, search for an AMI string value on https://cloud-images.ubuntu.com/locator/ec2/ and then replace that in the <code>ami</code> variable.</p> <p>For the backend in development we will be using terraform cloud (free for up to 5 users). In production we will be using S3 with Dynamo DB.</p> <p>Dynamo DB has state locking which prevents concurrent apply commands being executed at the same time.</p> <p>In dev: Check the setup above </p> <p>In prod: We first bootstrap the bucket and Dynamo DB table through Terraform then we continue with our normal setup. The provisioning files are in the <code>terraform/envs/prod/bootstrap</code> directory.  </p> <p>Another way is to make use of the <code>terraform-aws-modules/vpc/aws</code> module. This is the solution that we employed in this project.</p> <p>We have to setup the bootstrap workspace in the terraform cloud as we did for dev</p> <p>Then:</p> <pre><code>terraform login # to provide token for \ntask tf-apply-bootstrap\n</code></pre> <p>This creates the state bucket and DynamoDB locking table, along with anything else you have defined in the *.tf file(s). At this point, the Terraform state is still stored locally.</p> <p>Module terraform_state_backend also creates a new <code>prod-backend.tf</code> file (the name can be changed in the variables) that defines the S3+DB state backend.</p> <p>Info</p> <p>When running the bootstrap in Terraform Cloud, the <code>local_file</code> resource from <code>cloudposse/tfstate-backend</code> cannot persist files back into your Git repository. This is why you do not see a <code>backend.tf</code> file after a successful apply. Instead of relying on <code>local_file</code>, you should expose the S3 bucket, DynamoDB table, and region as outputs. After the bootstrap run, Terraform Cloud will print these outputs. You can then copy the generated backend snippet into a versioned <code>backend.tf</code> file in your repo.</p> <p>We use that configuration for our production <code>backend.tf</code> file.</p> <pre><code>terraform init --reconfigure # in prod/ directory\n\n# OR IF AND ONLY IF YOU RAN USING LOCAL BACKEND\nterraform init --force-copy # Terraform detects that you want to move your state to the S3 backend, and it does so per -auto-approve.\n</code></pre> <p>Now the state is stored in the S3 bucket, and the DynamoDB table will be used to lock the state to prevent concurrent modification. This concludes the one-time preparation. Now we can extend and modify our Terraform configuration as usual.</p> <p>Here\u2019s a finalised version of your MkDocs note with tightened structure, consistent formatting, and no ambiguity:</p>"},{"location":"2-project/setup/#destroying-bootstrap","title":"Destroying bootstrap","text":"<p>Important</p> <p>Please read this section in full before implementing.</p> <p>In this setup:</p> <ul> <li>Bootstrap runs in Terraform Cloud (remote backend).</li> <li>Bootstrap provisions an S3 bucket (<code>devopssean-prod-terraform-state</code>) and a DynamoDB table (<code>devopssean-prod-terraform-state-lock</code>).</li> <li>Other environments (<code>prod</code>, <code>staging</code>, <code>dev</code>) are configured to use those backend resources.</li> </ul> <p>If you want to destroy bootstrap and clean up, follow these steps.</p> <ol> <li> <p>Check dependencies</p> </li> <li> <p>Confirm that no environments (<code>prod</code>, <code>staging</code>, <code>dev</code>) are still using the bootstrap S3 bucket and DynamoDB table.</p> </li> <li>If they are, migrate them to Terraform Cloud first. Otherwise they will break.</li> </ol>"},{"location":"2-project/setup/#migration-procedure","title":"Migration procedure","text":"<p>Step 1 \u2013 Create Terraform Cloud workspaces</p> <ul> <li>In Terraform Cloud, create a separate workspace for each environment (<code>prod</code>, <code>staging</code>, <code>dev</code>).</li> <li>Point each workspace to the corresponding environment folder in your repository.</li> <li>Add AWS credentials or an OIDC role in workspace variables so Terraform Cloud can deploy infrastructure.</li> </ul> <p>Step 2 \u2013 Update backend configuration</p> <p>Replace the S3 backend in each environment\u2019s <code>backend.tf</code> with a Terraform Cloud block:</p> <pre><code> terraform {\n   cloud {\n     organization = \"devopssean\"\n\n     workspaces {\n       name = \"prod\"   # or staging/dev as appropriate\n     }\n   }\n }\n</code></pre> <p>Remove the old <code>backend \"s3\"</code> block entirely.</p> <p>Step 3 \u2013 Re-initialise with migration</p> <p>In each environment folder:</p> <pre><code>terraform init --migrate-state\n</code></pre> <p>Terraform will:</p> <ul> <li>Detect the backend change (S3 \u2192 Terraform Cloud).</li> <li>Prompt to migrate state.</li> <li>Move <code>.tfstate</code> from S3 into Terraform Cloud.</li> </ul> <p>For automation, use:</p> <pre><code>terraform init --migrate-state --force-copy\n</code></pre> <p>Step 4 \u2013 Validate</p> <ul> <li>In Terraform Cloud, check that each workspace now shows existing resources.</li> <li>Run <code>terraform plan</code> to confirm there is no drift.</li> </ul> <p>Step 5 \u2013 Destroy bootstrap</p> <p>Once all environments are migrated:</p> <pre><code>cd envs/prod/bootstrap\ntask tf-destroy-bootstrap\n</code></pre> <p>This deletes the S3 bucket, DynamoDB table, and any other bootstrap resources.</p> <p>Risks if skipped</p> <ul> <li> <p>If you destroy bootstrap first, the S3 bucket and DynamoDB table are lost.   Then <code>terraform init --migrate-state</code> cannot read the old state, and environments will behave as if they are fresh deployments (risk of duplicate resources).</p> </li> <li> <p>Go to bootstrap folder</p> </li> </ul> <pre><code>cd envs/prod/bootstrap\n</code></pre> <ol> <li>Destroy bootstrap resources</li> </ol> <pre><code>task tf-destroy-bootstrap\n</code></pre> <p>This removes the backend bucket, DynamoDB table, and all other bootstrap resources.</p> <ol> <li> <p>Verify state</p> </li> <li> <p>Bootstrap workspace in Terraform Cloud should show <code>0</code> resources.</p> </li> <li>S3 should no longer have a bucket named <code>devopssean-prod-terraform-state</code>.</li> <li>DynamoDB should no longer have a table named <code>devopssean-prod-terraform-state-lock</code>.</li> </ol> <p>Important</p> <p>After this, any <code>prod</code>, <code>staging</code>, or <code>dev</code> environment still pointing to the old backend will fail. Always migrate them to Terraform Cloud before destroying bootstrap.</p>"},{"location":"2-project/terraform/","title":"Terraform Essentials for DevOps","text":""},{"location":"2-project/terraform/#core-blocks","title":"Core Blocks","text":"<p>These are the most important Terraform configuration blocks for DevOps tasks:</p> <ul> <li><code>provider</code></li> </ul> <p>Defines the infrastructure platform (e.g., AWS, Azure, GCP).</p> <ul> <li><code>resource</code></li> </ul> <p>Provisions infrastructure components like servers, databases, and networks.</p> <ul> <li><code>variable</code></li> </ul> <p>Declares input values to parameterise configurations.</p> <ul> <li><code>output</code></li> </ul> <p>Exposes values (like IP addresses, URLs) after deployment.</p> <ul> <li><code>module</code></li> </ul> <p>Organises and reuses Terraform configurations for better structure and DRY code.</p> <ul> <li><code>locals</code></li> </ul> <p>Defines local values to simplify expressions and avoid repetition.</p>"},{"location":"2-project/terraform/#sometimes-used","title":"Sometimes Used","text":"<ul> <li><code>data</code></li> </ul> <p>Retrieves existing resources from the provider (e.g., latest AMI, existing VPC).</p> <ul> <li><code>terraform</code></li> </ul> <p>Configures backend settings (e.g., for remote state storage with S3, GCS).</p>"},{"location":"2-project/terraform/#resource-vs-module","title":"Resource vs Module","text":"<p>When to use which:</p> <ul> <li> <p>If you want fine-grained control or need something not covered by a module \u2192 use provider resources directly from the AWS provider docs.</p> </li> <li> <p>If you want faster, standardised setups (VPC, RDS, ECS, S3) \u2192 use the terraform-aws-modules modules, pinned to a version.</p> </li> </ul>"},{"location":"2-project/terraform/#data-types","title":"Data Types","text":"<p>Terraform supports several variable types. Below is a complete list with examples.</p>"},{"location":"2-project/terraform/#primitive-types","title":"Primitive Types","text":"<ul> <li>string    Text values.</li> </ul> <pre><code>variable \"instance_type\" {\n  type    = string\n  default = \"t2.micro\"\n}\n</code></pre> <ul> <li>number    Integers or floats.</li> </ul> <pre><code>variable \"instance_count\" {\n  type    = number\n  default = 3\n}\n</code></pre> <ul> <li>bool    Boolean values (<code>true</code> or <code>false</code>).</li> </ul> <pre><code>variable \"enable_monitoring\" {\n  type    = bool\n  default = true\n}\n</code></pre>"},{"location":"2-project/terraform/#collection-types","title":"Collection Types","text":"<ul> <li>list()    Ordered sequence of values of the same type. <pre><code>variable \"availability_zones\" {\n  type    = list(string)\n  default = [\"us-east-1a\", \"us-east-1b\"]\n}\n</code></pre> <ul> <li>set()    Unordered collection of unique values of the same type. <pre><code>variable \"security_groups\" {\n  type    = set(string)\n  default = [\"sg-12345\", \"sg-67890\"]\n}\n</code></pre> <ul> <li>map()    Key-value pairs with keys as strings and values of the same type. <pre><code>variable \"tags\" {\n  type = map(string)\n  default = {\n    Environment = \"dev\"\n    Owner       = \"team-a\"\n  }\n}\n</code></pre>"},{"location":"2-project/terraform/#structural-types","title":"Structural Types","text":"<ul> <li>object({...})    Group of named attributes, each with its own type.</li> </ul> <pre><code>variable \"server_config\" {\n  type = object({\n    name     = string\n    cpu      = number\n    memory   = number\n    priority = bool\n  })\n  default = {\n    name     = \"webserver\"\n    cpu      = 2\n    memory   = 4096\n    priority = true\n  }\n}\n</code></pre> <ul> <li>tuple([...])    Sequence of elements where each position can have a different type.</li> </ul> <pre><code>variable \"db_info\" {\n  type = tuple([string, number, bool])\n  default = [\"mysql\", 3306, true]\n}\n</code></pre>"},{"location":"2-project/terraform/#special-types","title":"Special Types","text":"<ul> <li>any    Accepts any type. Not recommended for strict validation.</li> </ul> <pre><code>variable \"raw_input\" {\n  type = any\n}\n</code></pre> <p>Terraform variable names must use letters, digits, and underscores only.</p> <ul> <li>Valid:</li> </ul> <pre><code>variable \"instance_type\" {}\nvariable \"db_user1\" {}\nvariable \"enable_logging\" {}\n</code></pre> <ul> <li>Invalid (will cause an error):</li> </ul> <pre><code>variable \"instance-type\" {}   # hyphens not allowed\nvariable \"db-user\" {}\n</code></pre> <p>Hyphens (<code>-</code>) are only allowed in the values or resource names, not in variable identifiers.</p>"},{"location":"2-project/terraform/#terraform-cheat-sheet","title":"Terraform Cheat Sheet","text":""},{"location":"2-project/terraform/#provider","title":"Provider","text":"<p>Defines the cloud or infrastructure platform.</p> <pre><code>provider \"aws\" {\n    region = var.aws_region\n}\n</code></pre>"},{"location":"2-project/terraform/#resource","title":"Resource","text":"<p>Creates and manages infrastructure components.</p> <pre><code>resource \"aws_instance\" \"web\" {\n    ami           = var.ami_id\n    instance_type = var.instance_type\n    tags = {\n    Name = \"web-server\"\n    }\n}\n</code></pre>"},{"location":"2-project/terraform/#variable","title":"Variable","text":"<p>Allows configuration reuse and customization.</p> <pre><code>variable \"instance_type\" {\n    type    = string\n    default = \"t2.micro\"\n}\n</code></pre> <p>Usage:</p> <pre><code>instance_type = var.instance_type\n</code></pre>"},{"location":"2-project/terraform/#output","title":"Output","text":"<p>Exposes values after deployment.</p> <pre><code>output \"web_ip\" {\n    value = aws_instance.web.public_ip\n}\n</code></pre>"},{"location":"2-project/terraform/#module","title":"Module","text":"<p>Organises and reuses configuration.</p> <pre><code>module \"vpc\" {\n    source = \"./modules/vpc\"\n    cidr   = var.vpc_cidr\n}\n</code></pre>"},{"location":"2-project/terraform/#locals","title":"Locals","text":"<p>Simplifies logic and avoids repetition.</p> <pre><code>locals {\n    subnet_cidrs = [\n    cidrsubnet(var.vpc_cidr, 8, 1),\n    cidrsubnet(var.vpc_cidr, 8, 2),\n    ]\n}\n</code></pre>"},{"location":"2-project/terraform/#data-source","title":"Data Source","text":"<p>Pulls in external or existing infrastructure.</p> <pre><code>data \"aws_ami\" \"ubuntu\" {\n    most_recent = true\n    owners      = [\"099720109477\"]\n    filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"]\n    }\n}\n</code></pre>"},{"location":"2-project/terraform/#terraform-block","title":"Terraform Block","text":"<p>Configures version and remote state settings.</p> <pre><code>terraform {\n    required_version = \"&gt;= 1.0.0\"\n    backend \"s3\" {\n    bucket         = \"tf-state-bucket\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"eu-west-1\"\n    dynamodb_table = \"tf-lock\"\n    }\n}\n</code></pre>"},{"location":"2-project/terraform/#quick-glossary","title":"Quick Glossary","text":"Block Purpose <code>provider</code> Defines infrastructure platform <code>resource</code> Creates/manages infra components <code>variable</code> Declares configurable values <code>output</code> Exposes outputs from applied infrastructure <code>module</code> Reuses organized code modules <code>locals</code> Stores computed values for reuse <code>data</code> Fetches existing resources <code>terraform</code> Configures backend and versioning"},{"location":"2-project/terraform/#devops-pro-tips","title":"DevOps Pro Tips","text":"<ul> <li>Use remote state with locking in team settings (<code>terraform</code> block).</li> <li>Break infrastructure into modules for reuse and clarity.</li> <li>Always pin versions of Terraform and providers.</li> <li>Use <code>data</code> to avoid bloating state with existing infra.</li> <li>Apply consistent naming for better collaboration.</li> </ul> <p>Version 3 - Each TF module in its own git repo with versioning (typical repo name: <code>terraform-{provider}-{module}</code> (e.g <code>terraform-aws-vpc</code>).</p> <p>Then inside you would have the normal TF files \u2192 main, variables, outputs, versions, etc.</p> <p>Then, after git commit, you <code>git tag x.x.x</code>, then push with <code>-- tags</code>. Now, in the main of each module, reference the git link with the tag as a source in the module resource</p> <p>When changes are made to the module, push with a new version number. This can get cumbersome if there are too many repo modules so it's best to use reuseable modules across the microservices.</p> <p> </p>"},{"location":"2-project/terraform/#my-current-stack","title":"My current Stack","text":""},{"location":"2-project/terraform/#local-development","title":"Local Development","text":"Layer Tool/Component Purpose Local Backend <code>terraform cloud</code> backend Stores Terraform state files for isolated development. Workspaces Terraform Workspaces Manages multiple environments (e.g., dev, test) within the same config. Mock Providers LocalStack, Docker Simulates cloud services locally for testing without incurring costs. Testing Framework Terratest or <code>terraform plan</code> in CI Facilitates automated testing of Terraform modules and configurations. Linting &amp; Formatting <code>tflint</code>, <code>terraform fmt</code> Ensures code quality and adherence to best practices."},{"location":"2-project/terraform/#production","title":"Production","text":"Layer Tool/Component Purpose Remote Backend S3 + DynamoDB (AWS) or Terraform Cloud (free tier) Stores state files remotely with locking and versioning capabilities. Version Control GitHub, GitLab Manages infrastructure code and enables collaboration. CI/CD Integration GitHub Actions Automates testing and deployment of infrastructure changes. Secrets Management AWS Secrets Manager Secures sensitive information used in configurations. Policy Enforcement OPA (with Conftest) Enforces compliance and governance policies on infrastructure changes. Monitoring &amp; Alerts Basic CloudWatch / Prometheus exporters Monitors infrastructure health and performance."},{"location":"2-project/terraform/#terraform-command-cheat-sheet","title":"Terraform Command Cheat Sheet","text":""},{"location":"2-project/terraform/#initialisation-and-setup","title":"Initialisation and Setup","text":"<pre><code>terraform init            # Initialise working directory, install providers, configure backend\nterraform init -upgrade   # Upgrade provider plugins\nterraform workspace list  # List workspaces\nterraform workspace new &lt;name&gt;  # Create new workspace\nterraform workspace select &lt;name&gt;  # Switch workspace\n</code></pre>"},{"location":"2-project/terraform/#validation-and-formatting","title":"Validation and Formatting","text":"<pre><code>terraform fmt             # Auto-format .tf files\nterraform validate        # Validate syntax and internal consistency\nterraform providers       # List providers required by configuration\n</code></pre>"},{"location":"2-project/terraform/#planning","title":"Planning","text":"<pre><code>terraform plan                          # Show execution plan\nterraform plan -out=tfplan              # Save plan to file\nterraform show tfplan                   # Show saved plan in human-readable form\nterraform show -json tfplan &gt; plan.json # Output plan in JSON\n</code></pre>"},{"location":"2-project/terraform/#applying","title":"Applying","text":"<pre><code>terraform apply                         # Apply with interactive approval\nterraform apply -auto-approve           # Apply without prompt\nterraform apply tfplan                  # Apply previously saved plan\n</code></pre>"},{"location":"2-project/terraform/#destroying","title":"Destroying","text":"<pre><code>terraform destroy                       # Destroy managed infrastructure\nterraform destroy -target=aws_instance.my_vm  # Destroy specific resource\n</code></pre>"},{"location":"2-project/terraform/#state-management","title":"State Management","text":"<pre><code>terraform state list                    # List resources in state\nterraform state show &lt;resource&gt;         # Show details of one resource\nterraform state rm &lt;resource&gt;           # Remove resource from state\nterraform state mv &lt;src&gt; &lt;dst&gt;          # Move resource in state\nterraform refresh                       # Sync state with real infrastructure\n</code></pre>"},{"location":"2-project/terraform/#importing","title":"Importing","text":"<pre><code>terraform import &lt;resource&gt; &lt;id&gt;        # Import existing infra into state\n</code></pre>"},{"location":"2-project/terraform/#output_1","title":"Output","text":"<pre><code>terraform output                        # Show all outputs\nterraform output &lt;name&gt;                 # Show specific output\nterraform output -json                  # JSON output\n</code></pre>"},{"location":"2-project/terraform/#graphing","title":"Graphing","text":"<p><pre><code>terraform graph | dot -Tpng &gt; graph.png # Generate dependency graph\n</code></pre> In Terraform, modules are reusable units of configuration. A module is just a directory containing <code>.tf</code> files.</p>"},{"location":"2-project/terraform/#modules","title":"Modules","text":"<p>Terraform always has at least two levels:</p> <ul> <li>Root module \u2192 the directory where you run <code>terraform init/plan/apply</code>.</li> <li>Child modules \u2192 any module blocks referenced from the root (or other child) modules.</li> </ul>"},{"location":"2-project/terraform/#1-why-use-modules","title":"1. Why use modules?","text":"<ul> <li>Reuse across projects and environments.</li> <li>Standardise infrastructure (network, IAM, compute).</li> <li>Reduce duplication by passing variables.</li> <li>Enforce best practices by versioning modules in a registry.</li> </ul>"},{"location":"2-project/terraform/#2-structure-of-a-basic-module","title":"2. Structure of a basic module","text":"<p>Example: <code>modules/network/</code></p> <pre><code>modules/\n\u2514\u2500\u2500 network/\n    \u251c\u2500\u2500 main.tf\n    \u251c\u2500\u2500 variables.tf\n    \u251c\u2500\u2500 outputs.tf\n</code></pre> <ul> <li><code>main.tf</code> \u2192 resources</li> <li><code>variables.tf</code> \u2192 input variables</li> <li><code>outputs.tf</code> \u2192 exported values</li> </ul>"},{"location":"2-project/terraform/#3-calling-a-module","title":"3. Calling a module","text":"<p>From your root module:</p> <pre><code>module \"vpc\" {\n  source = \"./modules/network\"  # local path, Git URL, or registry\n  cidr_block = \"10.0.0.0/16\"\n  name       = \"dev-vpc\"\n}\n</code></pre>"},{"location":"2-project/terraform/#4-sources","title":"4. Sources","text":"<p>Modules can be sourced from:</p> <ul> <li>Local path</li> </ul> <p><pre><code>source = \"./modules/network\"\n</code></pre> * Terraform Registry</p> <p><pre><code>source  = \"terraform-aws-modules/vpc/aws\"\nversion = \"5.0.0\"\n</code></pre> * Git repo</p> <pre><code>source = \"git::https://github.com/your-org/tf-modules.git//network?ref=v1.0.0\"\n</code></pre>"},{"location":"2-project/terraform/#5-variables-and-outputs","title":"5. Variables and outputs","text":""},{"location":"2-project/terraform/#inside-module-variablestf","title":"Inside module (<code>variables.tf</code>):","text":"<pre><code>variable \"cidr_block\" {\n  type        = string\n  description = \"VPC CIDR block\"\n}\n\nvariable \"name\" {\n  type        = string\n  description = \"Name for the VPC\"\n}\n</code></pre>"},{"location":"2-project/terraform/#inside-module-outputstf","title":"Inside module (<code>outputs.tf</code>):","text":"<pre><code>output \"vpc_id\" {\n  value = aws_vpc.main.id\n}\n</code></pre>"},{"location":"2-project/terraform/#in-root-module","title":"In root module:","text":"<pre><code>module \"vpc\" {\n  source     = \"./modules/network\"\n  cidr_block = \"10.0.0.0/16\"\n  name       = \"dev-vpc\"\n}\n\noutput \"vpc_id\" {\n  value = module.vpc.vpc_id\n}\n</code></pre>"},{"location":"2-project/terraform/#6-meta-arguments-with-modules","title":"6. Meta-arguments with modules","text":"<p>Modules accept:</p> <ul> <li><code>count</code></li> <li><code>for_each</code></li> <li><code>depends_on</code></li> <li><code>providers</code></li> </ul> <p>Example:</p> <pre><code>module \"vpcs\" {\n  source = \"./modules/network\"\n  for_each = {\n    dev  = \"10.0.0.0/16\"\n    prod = \"10.1.0.0/16\"\n  }\n  cidr_block = each.value\n  name       = each.key\n}\n</code></pre>"},{"location":"2-project/terraform/#7-best-practices","title":"7. Best practices","text":"<ul> <li>Keep modules small and focused (e.g. <code>network</code>, <code>iam</code>, <code>compute</code>).</li> <li>Use versioned modules from a Git repo or Terraform Registry.</li> <li>Do not put provider blocks inside child modules (pass providers from root).</li> <li>Expose only useful outputs.</li> <li>Keep modules stateless: no hardcoded values.</li> <li>Test modules in isolation before reusing.</li> </ul>"},{"location":"2-project/terraform/#8-risks","title":"8. Risks","text":"<ul> <li>Over-abstraction: too many generic variables makes modules hard to use.</li> <li>Provider inside module causes provider conflicts.</li> <li>Sensitive values passed through outputs are exposed in state.</li> <li>If using <code>count</code>/<code>for_each</code>, resource addressing can break on refactor.</li> </ul> <p>There are Terraform modules that can spin up entire cloud setups, not just single resources.</p>"},{"location":"2-project/terraform/#1-community-official-modules","title":"1. Community / Official Modules","text":"<ul> <li> <p>Terraform AWS Modules (terraform-aws-modules):   These are well-maintained, production-grade modules for AWS. Examples:</p> </li> <li> <p><code>terraform-aws-modules/vpc/aws</code> \u2192 full VPC setup (subnets, routing, NAT, IGW).</p> </li> <li><code>terraform-aws-modules/eks/aws</code> \u2192 fully working EKS (Kubernetes) cluster with node groups, IAM roles, and networking.</li> <li><code>terraform-aws-modules/ec2-instance/aws</code> \u2192 full EC2 provisioning with security groups, IAM, etc.</li> </ul> <p>These modules can be combined to form a complete infrastructure (network + compute + IAM).</p>"},{"location":"2-project/terraform/#2-stacks-and-blueprints","title":"2. Stacks and Blueprints","text":"<p>Vendors and open-source projects publish stacks (collections of modules) that bring up entire environments.</p> <ul> <li>Gruntwork IaC Library (commercial) \u2192 prebuilt modules covering VPC, ECS, EKS, CI/CD, Vault, Consul.</li> <li>Cloud Posse modules (cloudposse) \u2192 composable modules that can build entire AWS org structures.</li> <li>HashiCorp AWS Reference Architecture (terraform-aws-landing-zone) \u2192 starting point for a full AWS account structure.</li> </ul>"},{"location":"2-project/terraform/#3-cloud-native-reference-projects","title":"3. Cloud-Native Reference Projects","text":"<ul> <li>AWS Control Tower + Terraform \u2192 sets up a multi-account AWS org with logging, guardrails, SSO.</li> <li>Google Cloud Foundation Toolkit (CFT) \u2192 Terraform modules for complete GCP environments.</li> <li>Azure Landing Zones (Enterprise Scale) \u2192 modules for identity, networking, governance.</li> </ul>"},{"location":"2-project/terraform/#4-diy-patterns","title":"4. DIY Patterns","text":"<p>You can also wire modules together for a full cloud setup:</p> <ul> <li>Root module defines environments (<code>dev</code>, <code>staging</code>, <code>prod</code>).</li> <li> <p>Includes child modules:</p> </li> <li> <p><code>network</code> (VPC, subnets, routes)</p> </li> <li><code>security</code> (IAM roles, policies, KMS)</li> <li><code>compute</code> (EKS, ECS, or EC2)</li> <li><code>storage</code> (S3, RDS, DynamoDB)</li> <li>One <code>terraform apply</code> spins up a ready-to-use environment.</li> </ul>"},{"location":"2-project/terraform/#trade-offs","title":"Trade-offs","text":"<ul> <li>Pros: Fast bootstrap, proven patterns, less boilerplate.</li> <li>Cons: Opinionated (you inherit module defaults), dependency management between large modules can be messy, risk of \u201cblack box\u201d complexity.</li> </ul>"},{"location":"2-project/terraform/#passing-sensitive-values","title":"Passing sensitive values","text":"<p>In Terraform, sensitive variables are values that should not be displayed in plaintext in logs, CLI output, or state files where possible. They are used for things like passwords, API keys, secrets, etc.</p>"},{"location":"2-project/terraform/#how-to-declare-a-sensitive-variable","title":"How to declare a sensitive variable","text":"<pre><code>variable \"db_password\" {\n  description = \"Database password\"\n  type        = string\n  sensitive   = true\n}\n</code></pre> <p>When <code>sensitive = true</code>:</p> <ul> <li>Terraform CLI masks the value with <code>\"sensitive\"</code> in outputs.</li> <li><code>terraform plan</code> and <code>terraform apply</code> will not print the value.</li> <li>However, the raw value still exists in the Terraform state file (<code>terraform.tfstate</code>).</li> </ul>"},{"location":"2-project/terraform/#using-sensitive-variables-in-modules","title":"Using sensitive variables in modules","text":"<pre><code>module \"db\" {\n  source      = \"./modules/db\"\n  db_password = var.db_password\n}\n</code></pre>"},{"location":"2-project/terraform/#sensitive-outputs","title":"Sensitive outputs","text":"<pre><code>output \"db_password\" {\n  value     = var.db_password\n  sensitive = true\n}\n</code></pre> <p>This prevents the output from being shown in the CLI unless you explicitly request it:</p> <pre><code>terraform output db_password        # masked\nterraform output -json db_password  # reveals raw value\n</code></pre>"},{"location":"2-project/terraform/#sources-for-sensitive-values","title":"Sources for sensitive values","text":"<ul> <li>Environment variables</li> </ul> <pre><code>export TF_VAR_db_password=\"supersecret\"\nterraform apply\n</code></pre> <ul> <li>.tfvars file (never commit this):</li> </ul> <pre><code>db_password = \"supersecret\"\n</code></pre> <ul> <li>Terraform Cloud / Workspaces \u2192 set as workspace variables, marked sensitive.</li> <li>Secret managers (recommended): inject from AWS Secrets Manager, Vault, or SSM via data sources.</li> </ul>"},{"location":"2-project/terraform/#limitations","title":"Limitations","text":"<ul> <li>Sensitive values still exist in <code>terraform.tfstate</code>. Anyone with access to state storage can read them.</li> <li>To mitigate, always use a remote backend (e.g. S3 + DynamoDB, Terraform Cloud, Vault).</li> <li>Sensitive only prevents accidental exposure in CLI/logs, not storage.</li> </ul>"},{"location":"2-project/terraform/#best-practices","title":"Best practices","text":"<ol> <li>Mark all secrets (<code>passwords</code>, <code>API keys</code>, <code>tokens</code>) as <code>sensitive = true</code>.</li> <li>Never commit <code>.tfvars</code> with secrets to git.</li> <li>Store secrets in secret managers or inject via pipelines.</li> <li>Protect state files: encrypt in S3, restrict access, or use Terraform Cloud.</li> <li>Use <code>prevent_destroy</code> lifecycle for critical resources that depend on secrets.</li> </ol>"},{"location":"2-project/terraform/#meta-arguments","title":"Meta Arguments","text":"<p>In Terraform, meta-arguments are special arguments you can add to any resource or module block. They control Terraform\u2019s behaviour, not the resource itself. They are evaluated by Terraform Core before provider logic.</p>"},{"location":"2-project/terraform/#common-meta-arguments","title":"Common Meta-Arguments","text":""},{"location":"2-project/terraform/#1-count","title":"1. <code>count</code>","text":"<p>Create multiple instances of a resource.</p> <pre><code>resource \"aws_instance\" \"example\" {\n  count = 3\n  ami   = \"ami-123456\"\n  type  = \"t2.micro\"\n}\n</code></pre> <p>Accessible via index:</p> <pre><code>aws_instance.example[0].id\n</code></pre>"},{"location":"2-project/terraform/#2-for_each","title":"2. <code>for_each</code>","text":"<p>Iterate over a map or set of strings. More flexible than <code>count</code>.</p> <pre><code>resource \"aws_s3_bucket\" \"b\" {\n  for_each = toset([\"logs\", \"images\", \"data\"])\n  bucket   = \"myapp-${each.key}\"\n}\n</code></pre> <p>Access: <code>aws_s3_bucket.b[\"logs\"].id</code></p>"},{"location":"2-project/terraform/#3-provider","title":"3. <code>provider</code>","text":"<p>Choose a specific provider configuration (useful for multi-region/multi-account).</p> <pre><code>provider \"aws\" {\n  alias  = \"us_west\"\n  region = \"us-west-2\"\n}\n\nresource \"aws_instance\" \"west\" {\n  provider = aws.us_west\n  ami      = \"ami-789012\"\n  type     = \"t2.micro\"\n}\n</code></pre>"},{"location":"2-project/terraform/#4-depends_on","title":"4. <code>depends_on</code>","text":"<p>Force explicit dependency when Terraform cannot infer it automatically.</p> <pre><code>resource \"aws_instance\" \"app\" {\n  ami           = \"ami-123456\"\n  type          = \"t2.micro\"\n  depends_on    = [aws_s3_bucket.logs]\n}\n</code></pre>"},{"location":"2-project/terraform/#5-lifecycle","title":"5. <code>lifecycle</code>","text":"<p>Fine-tune create/update/destroy behaviour.</p> <pre><code>resource \"aws_s3_bucket\" \"state\" {\n  bucket = \"terraform-state\"\n\n  lifecycle {\n    prevent_destroy = true       # disallow destroy\n    create_before_destroy = true # replacement strategy\n    ignore_changes = [tags]      # ignore drift on tags\n  }\n}\n</code></pre>"},{"location":"2-project/terraform/#6-provisioner-not-recommended-for-production","title":"6. <code>provisioner</code> (not recommended for production)","text":"<p>Run local or remote scripts after create/destroy.</p> <pre><code>resource \"aws_instance\" \"app\" {\n  provisioner \"local-exec\" {\n    command = \"echo ${self.public_ip} &gt;&gt; hosts\"\n  }\n}\n</code></pre> <p>Better to use config management tools (Ansible, cloud-init).</p>"},{"location":"2-project/terraform/#7-connection-used-with-provisioners","title":"7. <code>connection</code> (used with provisioners)","text":"<p>Define how to connect to the resource.</p> <pre><code>connection {\n  type     = \"ssh\"\n  user     = \"ec2-user\"\n  host     = self.public_ip\n  private_key = file(\"~/.ssh/id_rsa\")\n}\n</code></pre>"},{"location":"2-project/terraform/#at-module-level","title":"At Module Level","text":"<p>Modules also support meta-arguments:</p> <ul> <li><code>count</code></li> <li><code>for_each</code></li> <li><code>depends_on</code></li> <li><code>providers</code></li> </ul> <p>Example:</p> <pre><code>module \"network\" {\n  source = \"./modules/network\"\n  for_each = {\n    dev  = \"10.0.0.0/16\"\n    prod = \"10.1.0.0/16\"\n  }\n  cidr_block = each.value\n}\n</code></pre>"},{"location":"2-project/terraform/#best-practices_1","title":"Best Practices","text":"<ul> <li>Prefer <code>for_each</code> over <code>count</code> for clarity (works with maps and stable addressing).</li> <li>Use <code>depends_on</code> sparingly\u2014most dependencies are inferred automatically.</li> <li>Always use <code>lifecycle.prevent_destroy = true</code> for critical resources like state buckets.</li> <li>Avoid provisioners unless no other option exists.</li> </ul>"},{"location":"2-project/terraform/#testing","title":"Testing","text":"<p>Terraform supports automated testing, but not traditional \"unit tests\" like in application code. Testing Terraform usually means validating configuration, planning, and applying against real or mocked infrastructure.</p>"},{"location":"2-project/terraform/#1-built-in-validation","title":"1. Built-in validation","text":"<ul> <li><code>terraform validate</code> \u2192 checks syntax and internal references.</li> <li><code>terraform plan</code> \u2192 dry-run to see what changes will be applied.</li> <li>These catch obvious issues, but not logic errors or infrastructure behaviour.</li> </ul>"},{"location":"2-project/terraform/#2-unit-style-testing-with-mocks","title":"2. Unit-style testing with mocks","text":"<ul> <li>Terraform plan + JSON output can be parsed and validated.</li> </ul> <pre><code>terraform plan -out=tfplan\nterraform show -json tfplan &gt; plan.json\n</code></pre> <p>You can then assert expected resources with tools like <code>jq</code> or custom scripts.</p> <ul> <li> <p>Terratest (Go library) \u2192 industry standard for Terraform testing.</p> </li> <li> <p>Uses Go\u2019s testing framework.</p> </li> <li>Can spin up infrastructure, run assertions (e.g. check an EC2 instance is reachable), and then destroy it.</li> <li> <p>Example:</p> <pre><code>func TestTerraformAwsExample(t *testing.T) {\n  terraformOptions := &amp;terraform.Options{\n    TerraformDir: \"../examples/aws\",\n  }\n  defer terraform.Destroy(t, terraformOptions)\n  terraform.InitAndApply(t, terraformOptions)\n  vpcId := terraform.Output(t, terraformOptions, \"vpc_id\")\n  assert.NotEmpty(t, vpcId)\n}\n</code></pre> </li> </ul>"},{"location":"2-project/terraform/#3-policy-and-compliance-tests","title":"3. Policy and compliance tests","text":"<ul> <li>Terraform Cloud / Sentinel \u2192 policy as code (enforce rules before apply).</li> <li>Open Policy Agent (OPA) / Conftest \u2192 test <code>.tf</code> or <code>.json</code> plans against compliance rules.   Example: ensure all S3 buckets have encryption enabled.</li> </ul>"},{"location":"2-project/terraform/#4-integration-end-to-end-testing","title":"4. Integration / End-to-End testing","text":"<ul> <li>Run Terraform in CI/CD (GitHub Actions, GitLab, Jenkins).</li> <li> <p>Pipeline stages:</p> </li> <li> <p><code>terraform fmt -check</code></p> </li> <li><code>terraform validate</code></li> <li><code>terraform plan -detailed-exitcode</code> (fail if unexpected changes)</li> <li>Optional: apply in a sandbox account \u2192 run integration tests (ping services, check IAM roles, etc.) \u2192 destroy.</li> </ul>"},{"location":"2-project/terraform/#5-specialised-tools","title":"5. Specialised tools","text":"<ul> <li>Checkov (by Bridgecrew) \u2192 static analysis for Terraform (security/compliance).</li> <li>TFLint \u2192 linter for Terraform, validates provider-specific rules.</li> <li>InSpec + Kitchen-Terraform \u2192 integration testing for infra after deployment.</li> </ul>"},{"location":"2-project/terraform/#best-practice-testing-strategy","title":"Best Practice Testing Strategy","text":"<ul> <li>Pre-commit \u2192 <code>terraform fmt</code>, <code>terraform validate</code>, <code>tflint</code>, <code>checkov</code>.</li> <li>CI/CD (unit-ish) \u2192 run <code>terraform plan</code>, parse JSON, assert expected resources.</li> <li>Integration (sandbox env) \u2192 deploy infra, test with Terratest/pytest, destroy.</li> <li>Compliance \u2192 enforce policies via Sentinel or OPA.</li> </ul>"},{"location":"2-project/terraform/#using-atlantis","title":"Using Atlantis","text":"<p>Atlantis is a self-hosted Terraform automation tool for pull-request workflows. It listens to Git webhooks, runs Terraform commands, and posts results back to PRs.</p> <ul> <li>Source: https://www.runatlantis.io</li> <li>Works with GitHub, GitLab, Bitbucket, Azure Repos.</li> </ul>"},{"location":"2-project/terraform/#core-workflow","title":"Core Workflow","text":"<ol> <li>Developer opens PR with Terraform changes.</li> <li>Atlantis auto-runs <code>terraform plan</code>.</li> <li>Atlantis posts the plan as a PR comment.</li> <li>Reviewer approves.</li> <li>Someone comments <code>atlantis apply</code>.</li> <li>Atlantis runs <code>terraform apply</code> from its server.</li> <li>PR merges after infra changes succeed.</li> </ol>"},{"location":"2-project/terraform/#supported-commands-commented-in-pr","title":"Supported Commands (commented in PR)","text":"<ul> <li> <p><code>atlantis plan</code></p> </li> <li> <p>Runs <code>terraform plan</code> in the repo/directory/workspace.</p> </li> <li> <p><code>atlantis apply</code></p> </li> <li> <p>Runs <code>terraform apply</code>.</p> </li> <li> <p><code>atlantis plan -d dir -w workspace</code></p> </li> <li> <p>Run plan in specific directory/workspace.</p> </li> <li> <p><code>atlantis apply -d dir -w workspace</code></p> </li> <li> <p>Apply only for a subset.</p> </li> <li> <p><code>atlantis unlock</code></p> </li> <li> <p>Unlock a stuck plan.</p> </li> </ul>"},{"location":"2-project/terraform/#setup-requirements","title":"Setup Requirements","text":"<ul> <li>Atlantis server (binary, Docker, Helm chart).</li> <li>Git provider integration: webhook + bot user/token.</li> <li>Access to Terraform backend (S3/DynamoDB, GCS, etc).</li> <li>IAM/credentials mounted into Atlantis container/VM.</li> </ul>"},{"location":"2-project/terraform/#global-config-reposyaml","title":"Global Config (<code>repos.yaml</code>)","text":"<p>Controls allowed repos and workflows. Example:</p> <pre><code>repos:\n- id: github.com/myorg/*\n  apply_requirements: [approved, mergeable]\n  workflow: default\n  allowed_overrides: [workflow]\n  allow_custom_workflows: true\n</code></pre>"},{"location":"2-project/terraform/#repo-config-atlantisyaml","title":"Repo Config (<code>atlantis.yaml</code>)","text":"<p>Defines projects and workflows for a repo. Example:</p> <pre><code>version: 3\nprojects:\n- name: staging\n  dir: terraform/staging\n  workspace: staging\n- name: prod\n  dir: terraform/prod\n  workspace: prod\n\nworkflows:\n  custom:\n    plan:\n      steps:\n        - init\n        - plan:\n            extra_args: [\"-lock=false\"]\n    apply:\n      steps:\n        - apply\n</code></pre>"},{"location":"2-project/terraform/#key-features","title":"Key Features","text":"<ul> <li>ChatOps style (trigger via PR comments).</li> <li>Multi-project support (<code>atlantis.yaml</code> can define many dirs/workspaces).</li> <li>Approval gates (require PR approval before <code>apply</code>).</li> <li>Policy controls (<code>apply_requirements</code>: approved, mergeable, etc).</li> <li>Custom workflows (inject <code>tflint</code>, <code>checkov</code>, <code>pre-commit</code>).</li> <li>Locking (prevents concurrent applies).</li> <li>Audit trail (all plans/applies tied to PRs and users).</li> </ul>"},{"location":"2-project/terraform/#best-practices_2","title":"Best Practices","text":"<ul> <li>Run Atlantis in a dedicated environment (Kubernetes, EC2, GCP VM).</li> <li>Use Terraform remote state (S3+DynamoDB, GCS, Terraform Cloud).</li> <li>Store credentials securely (vault, IRSA, workload identity).</li> <li>Define projects in <code>atlantis.yaml</code> to prevent running in the whole repo accidentally.</li> <li>Use custom workflows for linting, policy checks, security scans.</li> <li>Require PR approvals before <code>atlantis apply</code>.</li> </ul>"},{"location":"2-project/terraform/#pros-cons","title":"Pros / Cons","text":"<p>Pros:</p> <ul> <li>Open-source, self-hosted, free.</li> <li>Strong GitOps workflow.</li> <li>Easy collaboration (all plans visible in PRs).</li> <li>Extensible via workflows.</li> </ul> <p>Cons:</p> <ul> <li>Self-hosted \u2192 you manage upgrades, security, HA.</li> <li>Single-server bottleneck unless scaled.</li> <li>Limited UI (PR comments only).</li> <li>Doesn\u2019t manage secrets \u2192 you handle via env/volumes.</li> </ul>"},{"location":"2-project/terraform/#alternatives","title":"Alternatives","text":"<ul> <li>Terraform Cloud / Enterprise \u2192 SaaS, policy engine, built-in secrets.</li> <li>Spacelift \u2192 commercial, strong GitOps + policies.</li> <li>Env0, Scalr \u2192 similar to Atlantis but SaaS-based.</li> <li>DIY pipelines \u2192 GitHub Actions, GitLab CI running Terraform manually.</li> </ul>"},{"location":"2-project/terraform/#useful-commands-cheat","title":"Useful Commands Cheat","text":"<p>Inside PR:</p> <pre><code>atlantis plan                  # plan default project\natlantis apply                 # apply default project\natlantis plan -d terraform/dev # plan only in terraform/dev\natlantis apply -w prod         # apply only in prod workspace\natlantis unlock                # unlock stuck project\n</code></pre>"},{"location":"2-project/terraform/#debugging","title":"Debugging","text":"<ul> <li>Logs live in Atlantis server container/VM.</li> <li>Failed applies often caused by missing credentials or state lock.</li> <li>Use <code>--log-level debug</code> when running Atlantis for troubleshooting.</li> </ul>"},{"location":"2-project/uv-notes/","title":"uv Cheat Sheet","text":""},{"location":"2-project/uv-notes/#installation","title":"Installation","text":"<pre><code># Linux / macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows (PowerShell)\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Verify install\nuv --version\n</code></pre>"},{"location":"2-project/uv-notes/#projects","title":"Projects","text":"<pre><code># Create a new project in folder \"myproj\"\nuv init myproj\n\n# Create a new project in the current folder\nuv init\n</code></pre>"},{"location":"2-project/uv-notes/#dependencies","title":"Dependencies","text":"<pre><code># Add a package\nuv add requests\n\n# Add a package with version\nuv add django==4.2.7\n\n# Add a development dependency\nuv add --dev pytest\n\n# Remove a package\nuv remove requests\n</code></pre>"},{"location":"2-project/uv-notes/#locking-and-installing","title":"Locking and Installing","text":"<pre><code># Install all dependencies into the environment (creates uv.lock if missing)\nuv sync\n\n# Update dependencies to latest allowed versions\nuv sync --upgrade\n\n# Compile lock file from requirements input\nuv pip compile pyproject.toml\n\n# Sync environment to match lock file\nuv pip sync uv.lock\n</code></pre>"},{"location":"2-project/uv-notes/#virtual-environments","title":"Virtual Environments","text":"<pre><code># Create a virtual environment\nuv venv\n\n# Create with specific Python version\nuv venv --python 3.11\n\n# Show where environment is\nuv venv --path\n</code></pre>"},{"location":"2-project/uv-notes/#running-code","title":"Running Code","text":"<pre><code># Run Python inside environment\nuv run python\n\n# Run a script\nuv run myscript.py\n\n# Run a command with dependencies\nuv run pytest\n</code></pre>"},{"location":"2-project/uv-notes/#python-versions","title":"Python Versions","text":"<pre><code># List installed Python versions\nuv python list\n\n# Install Python 3.11\nuv python install 3.11\n\n# Upgrade Python 3.11 to latest patch\nuv python upgrade 3.11\n\n# Show default Python\nuv python pin\n</code></pre>"},{"location":"2-project/uv-notes/#inspecting","title":"Inspecting","text":"<pre><code># Show dependency tree\nuv tree\n\n# Show project metadata\nuv project show\n</code></pre>"},{"location":"2-project/uv-notes/#building-and-publishing","title":"Building and Publishing","text":"<pre><code># Build source distribution and wheel\nuv build\n\n# Publish to PyPI (requires credentials)\nuv publish\n</code></pre>"},{"location":"2-project/uv-notes/#tools","title":"Tools","text":"<pre><code># Install a tool globally (example: black)\nuv tool install black\n\n# Run a tool\nuv tool run black --version\n\n# List installed tools\nuv tool list\n\n# Remove a tool\nuv tool uninstall black\n</code></pre>"},{"location":"2-project/uv-notes/#useful-options","title":"Useful Options","text":"<pre><code># Dry run, show what would happen\n--dry-run\n\n# Use lowest compatible versions\n--resolution=lowest\n\n# Target a different Python version when resolving\n--python-version 3.10\n</code></pre> <p>Correct. The cheat sheet I gave did not include <code>uvx</code>. Here is the missing section.</p>"},{"location":"2-project/uv-notes/#uvx-cheat-sheet","title":"<code>uvx</code> Cheat Sheet","text":"<p><code>uvx</code> is a shortcut to run any Python package or script without pre-installing it. It automatically downloads the package into a temporary cache, runs it, and reuses cached copies on later runs. It is like <code>npx</code> in Node.js.</p>"},{"location":"2-project/uv-notes/#syntax","title":"Syntax","text":"<pre><code>uvx &lt;package&gt; [arguments...]\n</code></pre>"},{"location":"2-project/uv-notes/#examples","title":"Examples","text":"<pre><code># Run black without installing globally\nuvx black myfile.py\n\n# Run flake8\nuvx flake8 src/\n\n# Run httpie\nuvx http --version\n\n# Run Django admin script\nuvx django-admin startproject mysite\n</code></pre>"},{"location":"2-project/uv-notes/#pinning-versions","title":"Pinning Versions","text":"<pre><code># Run a specific version of black\nuvx black==23.9.1 --version\n</code></pre>"},{"location":"2-project/uv-notes/#with-python-scripts","title":"With Python Scripts","text":"<pre><code># Run a Python script that is not installed\nuvx -m http.server 8000\n</code></pre>"},{"location":"2-project/uv-notes/#notes","title":"Notes","text":"<ul> <li><code>uvx</code> installs packages into a cache under your user directory.</li> <li>First run is slower, later runs are instant (from cache).</li> <li>If you need to clear cache:</li> </ul> <p><pre><code>uv cache clean\n</code></pre> * Useful for tools (linters, formatters, build helpers) you do not want in your project dependencies. * Equivalent to <code>npx</code> in Node.js or <code>pipx run</code> in Python.</p> <p><code>uv tool list</code> will never show what is in <code>pyproject.toml</code>.</p> <p>Two separate systems:</p> Scope Command What it manages Where it records state Project dependencies <code>uv add</code>, <code>uv remove</code>, <code>uv sync</code> The packages your project uses <code>pyproject.toml</code> + <code>uv.lock</code> Global tools <code>uv tool install</code>, <code>uv tool uninstall</code>, <code>uv tool list</code> Stand-alone CLI tools, like <code>black</code>, <code>ruff</code>, <code>httpie</code> User\u2019s tool directory (<code>~/.local/share/uv/tools/</code> by default) <p>So if you want to see project dependencies, use:</p> <pre><code>uv tree          # dependency graph\n</code></pre> <p>If you want to see globally installed tools, then use:</p> <pre><code>uv tool list\n</code></pre> <p>They are intentionally kept separate.</p> <p>With <code>uv</code>, you never edit <code>[tool.poetry.dependencies]</code> like in Poetry. You only use standard PEP 621 fields in <code>pyproject.toml</code>.</p> <p>Two ways to add dependencies:</p>"},{"location":"2-project/uv-notes/#1-let-uv-edit-pyprojecttoml-for-you","title":"1. Let <code>uv</code> edit <code>pyproject.toml</code> for you","text":"<pre><code># Add a runtime dependency\nuv add requests\n\n# Add a dev dependency\nuv add --dev pytest\n</code></pre> <p>This will:</p> <ul> <li>Update <code>pyproject.toml</code> under <code>[project]</code> or <code>[tool.uv]</code> (depending on context).</li> <li>Regenerate <code>uv.lock</code>.</li> </ul>"},{"location":"2-project/uv-notes/#2-edit-pyprojecttoml-manually","title":"2. Edit <code>pyproject.toml</code> manually","text":"<p>Minimal example with dependencies written by hand:</p> <pre><code>[project]\nname = \"myproj\"\nversion = \"0.1.0\"\ndescription = \"Example project\"\nrequires-python = \"&gt;=3.10\"\n\ndependencies = [\n    \"requests&gt;=2.31\",\n    \"flask&gt;=2.3\",\n]\n\n[tool.uv]\ndev-dependencies = [\n    \"pytest&gt;=7.0\",\n]\n</code></pre> <p>Then run:</p> <pre><code>uv sync\n\n# List installed packages (table)\nuv pip list\n\n# Freeze environment (pip-compatible format)\nuv pip freeze\n</code></pre> <p>This will install what you declared and create/update <code>uv.lock</code>.</p>"},{"location":"2-project/uv-notes/#key-difference-from-poetry","title":"Key difference from Poetry","text":"<ul> <li>Poetry used <code>[tool.poetry.dependencies]</code> and <code>[tool.poetry.dev-dependencies]</code>.</li> <li>uv uses the PEP 621 standard <code>[project]</code> section for main dependencies.</li> <li>Dev dependencies live in <code>[tool.uv.dev-dependencies]</code>.</li> </ul>"},{"location":"2-project/tasks/0-overview/","title":"Overview","text":"<p>This Taskfile defines automation tasks to simplify development workflows and ensure consistency across environments.</p> <p>It abstracts repetitive shell commands into named tasks you can run with:</p> <pre><code>task &lt;task-name&gt; # runs a task\n</code></pre> <p>You can list all available tasks with:</p> <pre><code>task --list-all\n</code></pre> <p>For detailed details about taskfile use:</p> <ul> <li>Main Taskfile</li> <li>GitFlow Taskfile</li> </ul>"},{"location":"2-project/tasks/0-overview/#contact","title":"Contact","text":"<p>Questions or issues with GitFlow setup? Reach out via GitHub Issues or email at your.email@example.com.</p>"},{"location":"2-project/tasks/1-main-taskfile/","title":"Main Taskfile Overview","text":"<p>This section describes the purpose and layout of the main <code>Taskfile.yml</code> used in this project. The Taskfile defines automation tasks to simplify development workflows and ensure consistency across environments.</p>"},{"location":"2-project/tasks/1-main-taskfile/#purpose-of-this-taskfile","title":"Purpose of This Taskfile","text":"<p>This Taskfile provides command-line shortcuts for tasks like:</p> <ul> <li>Project setup</li> <li>Development environment bootstrapping</li> <li>Application deployment</li> <li>Local documentation serving</li> <li>Cleanup and teardown</li> </ul> <p>It abstracts repetitive shell commands into named tasks you can run with:</p> <pre><code>task &lt;task-name&gt;\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#core-sections","title":"Core Sections","text":""},{"location":"2-project/tasks/1-main-taskfile/#1-setup-initialization","title":"1. Setup &amp; Initialization","text":"<p>Includes tasks for:</p> <ul> <li>Installing dependencies</li> <li>Setting up local development tools</li> <li>Generating keys or configs (if applicable)</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#2-development-workflow","title":"2. Development Workflow","text":"<p>Common tasks for:</p> <ul> <li>Starting local services or dev containers</li> <li>Running dev servers</li> <li>Applying Kubernetes configs or local manifests</li> <li>Watching for file changes</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#3-documentation","title":"3. Documentation","text":"<p>Tasks to:</p> <ul> <li>Serve documentation locally (e.g., MkDocs)</li> <li>Build or deploy docs (if using GitHub Pages or mike)</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#4-deployment-automation","title":"4. Deployment &amp; Automation","text":"<p>Tasks may automate:</p> <ul> <li>Building and pushing Docker images</li> <li>Running linters or formatters</li> <li>Applying infrastructure changes (e.g., with Terraform)</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#5-cleanup-teardown","title":"5. Cleanup &amp; Teardown","text":"<p>Includes safe commands to:</p> <ul> <li>Tear down local clusters or containers</li> <li>Remove generated files or environments</li> <li>Reset state for fresh runs</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#typical-usage-flow","title":"Typical Usage Flow","text":"<p>A typical flow using this Taskfile might look like:</p> <ul> <li>Set up your environment:</li> </ul> <pre><code>task setup\n</code></pre> <ul> <li>Start development:</li> </ul> <pre><code>task dev\n</code></pre> <ul> <li>Serve documentation:</li> </ul> <pre><code>task docs\n</code></pre> <ul> <li>Clean up:</li> </ul> <pre><code>task cleanup\n</code></pre>"},{"location":"2-project/tasks/1-main-taskfile/#notes","title":"Notes","text":"<ul> <li>To list all available tasks:</li> </ul> <pre><code>task --list-all\n</code></pre> <ul> <li>Variables and flags can be passed to tasks like so:</li> </ul> <pre><code>task my-task &lt;var&gt;=&lt;value&gt;\n</code></pre> <ul> <li>You can structure task dependencies using <code>deps:</code> and reuse shell logic cleanly across environments.</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#tips","title":"Tips","text":"Key Description dotenv + env: auto-load .env files and allow task-specific overrides. vars: static or dynamic variables (via shell) for templated substitution. prompt: even for setup or prod, ask user before proceeding. preconditions: enforce environment state before running. deps: define ordering (serial) via deps for safety and repeatability. internal: hide helper tasks from user listings. platforms: restrict tasks to specific OS/arch. requires: enforce required input variables. status: skip tasks if outputs already exist."},{"location":"2-project/tasks/1-main-taskfile/#related-docs","title":"Related Docs","text":"<ul> <li>GitFlow Taskfile</li> <li>Getting Started</li> <li>Architecture Overview</li> </ul>"},{"location":"2-project/tasks/1-main-taskfile/#contact","title":"Contact","text":"<p>For issues or suggestions related to automation and task structure, open an issue or contact the maintainer at seannjela@outlook.com.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/","title":"GitFlow Taskfile Overview","text":"<p>This page explains the structure and functionality of the <code>Taskfile.gitflow.yml</code> file, which automates a standardized Git workflow using Git Flow conventions. This taskfile is designed to simplify and formalize branching, releasing, and hotfixing in projects that follow the GitFlow methodology.</p> <p>It is optional to use gitflow.</p> <p>If you do not want to use it, you can remove the <code>Taskfile.gitflow.yml</code> file and unlink it from the <code>Taskfile.yaml</code> file (remove the <code>includes</code> section). If you cannot find the section use <code>CTRL + F</code> to search for Taskfile.yaml.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#what-is-git-flow","title":"What is Git Flow?","text":"<p>Git Flow is a branching strategy that separates feature development from production releases. It introduces long-lived branches like <code>main</code> and <code>develop</code>, as well as temporary branches for features, releases, and hotfixes.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#purpose-of-this-taskfile","title":"Purpose of This Taskfile","text":"<p>The <code>Taskfile.gitflow.yml</code> automates repetitive Git Flow actions using the <code>task</code> CLI tool. It allows you to:</p> <ul> <li>Initialize a Git Flow structure with default branches and prefixes</li> <li>Create and finish feature branches</li> <li>Create release and hotfix branches</li> <li>Push and merge code with consistent naming and flow</li> <li>Eliminate manual mistakes in branch naming or merging</li> </ul> <p>This is especially useful in teams or long-running solo projects where structured release cycles are important.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#what-this-taskfile-automates","title":"What This Taskfile Automates","text":"<p>Here\u2019s a breakdown of what\u2019s covered:</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#1-initialization","title":"1. Initialization","text":"<ul> <li>Sets up Git Flow with <code>main</code> as the production branch and <code>develop</code> for ongoing work.</li> <li>Configures standard prefixes (<code>feature/</code>, <code>release/</code>, <code>hotfix/</code>, etc.).</li> <li>Ensures required branches (<code>main</code>, <code>develop</code>) exist locally and remotely.</li> <li>Optionally initializes the <code>gh-pages</code> branch for documentation deployments.</li> </ul> <p>This is typically run once at the start of the project using <code>task -t Taskfile.gitflow.yml init</code>.</p>"},{"location":"2-project/tasks/2-gitflow-taskfile/#2-feature-branch-management","title":"2. Feature Branch Management","text":"<ul> <li>Start a new feature branch from <code>develop</code></li> <li>Finish a feature by merging it back into <code>develop</code></li> <li>Automatically push changes to the remote</li> <li>Prevents common mistakes like forgetting to push or rebase</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#3-release-branch-management","title":"3. Release Branch Management","text":"<ul> <li>Create a release branch off <code>develop</code></li> <li>Optionally tag a version</li> <li>Merge into <code>main</code> and <code>develop</code></li> <li>Clean up the release branch</li> <li>Pushes changes and tags to the remote</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#4-hotfix-branch-management","title":"4. Hotfix Branch Management","text":"<ul> <li>Create a hotfix directly off <code>main</code> (for production issues)</li> <li>Merge back into both <code>main</code> and <code>develop</code></li> <li>Optionally tag the hotfix release</li> <li>Push changes and remove local branches</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#5-branch-cleanup-and-syncing","title":"5. Branch Cleanup and Syncing","text":"<ul> <li>Deletes local feature/release branches after merging</li> <li>Pulls and syncs remote branches as needed</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#typical-usage-flow","title":"Typical Usage Flow","text":"<ol> <li> <p>Initialize GitFlow structure <pre><code>task init\n</code></pre></p> </li> <li> <p>Start a new feature <pre><code>task feature:start name=\"add-login\"\n</code></pre></p> </li> <li> <p>Finish a feature <pre><code>task feature:finish name=\"add-login\"\n</code></pre></p> </li> <li> <p>Start a release <pre><code>task release:start version=\"1.0.0\"\n</code></pre></p> </li> <li> <p>Start a hotfix <pre><code>task hotfix:start version=\"1.0.1\"\n</code></pre></p> </li> <li> <p>Finish a release <pre><code>task release:finish version=\"1.0.0\"\n</code></pre></p> </li> <li> <p>Finish a hotfix <pre><code>task hotfix:finish version=\"1.0.1\"\n</code></pre></p> </li> </ol>"},{"location":"2-project/tasks/2-gitflow-taskfile/#when-should-you-use-this","title":"When Should You Use This?","text":"<p>Use this taskfile when:</p> <ul> <li>You want consistent branch names and GitFlow discipline</li> <li>You're working in long-lived projects that ship versioned releases</li> <li>You have documentation (e.g. via <code>mike</code>) that needs coordinated tagging</li> <li>You want to automate repetitive Git steps safely</li> </ul> <p>Avoid using it if:</p> <ul> <li>Your workflow is trunk-based (i.e., no <code>develop</code>)</li> <li>You're doing rapid prototyping without versioning</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#notes","title":"Notes","text":"<ul> <li>This taskfile assumes Git is already initialized and the remote origin is set.</li> <li>It is safe to re-run <code>init</code>; it won\u2019t overwrite existing GitFlow config.</li> <li>The file uses <code>{{.VAR_NAME}}</code> placeholders \u2014 these are defined in the task's command-line usage.</li> <li>You can see available tasks by running:</li> </ul> <pre><code>task --list-all\n</code></pre>"},{"location":"2-project/tasks/2-gitflow-taskfile/#related-docs","title":"Related Docs","text":"<ul> <li>Main Taskfile Overview</li> <li>Getting Started</li> <li>Architecture</li> </ul>"},{"location":"2-project/tasks/2-gitflow-taskfile/#contact","title":"Contact","text":"<p>Questions or issues with GitFlow setup? Reach out via GitHub Issues or email at seannjela@outlook.com.</p>"},{"location":"3-troubleshooting/0-overview/","title":"Troubleshooting Guide Overview","text":"<p>Welcome to the troubleshooting section of this documentation. This guide exists to help you diagnose and resolve common issues that may arise while using or setting up this project.</p> <p>Use the search bar at the top of this page to type keywords related to your issue (e.g., docker, cluster, permissions) and quickly find relevant entries.</p>"},{"location":"3-troubleshooting/0-overview/#what-youll-find-here","title":"What You'll Find Here","text":"<p>Each page in this section covers a specific issue or category of problems. These are meant to be: - Concise - Actionable - Focused on real problems encountered during development or deployment</p> <p>You can browse specific problem pages here:</p> <ul> <li>Problem 1</li> <li>Problem 2</li> <li>(More will be added as new issues are documented)</li> </ul> <p>Important Disclaimer</p> <p>This is a personal documentation site. I am maintaining it solo and cannot guarantee that every issue is fully documented or resolved. If you don\u2019t find a solution here, don\u2019t panic \u2014 most tools used in this project (e.g., Docker, Kubernetes, Terraform, Devbox) are widely adopted and well-supported. Try these resources first:</p> <ol> <li>ChatGPT or another AI assistant \u2013 Quick answers and guided debugging  </li> <li>YouTube \u2013 Visual walkthroughs for complex tools or errors  </li> <li>Google \u2013 Forums, GitHub Issues, and StackOverflow posts are often goldmines  </li> </ol>"},{"location":"3-troubleshooting/0-overview/#pro-tip","title":"Pro Tip","text":"<p>Tip</p> <p>When searching using the search bar above, include the name of the tool or parts of the error message (in quotes if exact), e.g.:</p> <p>\"helm install\" or \"helm\" \"chart not found\" or \"not found\" \"terraform apply\" or \"terraform\" \"invalid provider configuration\" or \"provider not found\" \"kubectl apply\" or \"kubectl\" \"namespace not found\" or \"namespace does not exist\"</p> <p>Thank you for your patience and initiative \u2014 the more we learn from problems, the better this documentation will become.</p>"},{"location":"3-troubleshooting/1-problem1/","title":"Problem Title (Short and Specific)","text":"<p>A short one-liner summary of the issue, e.g., \u201cHelm chart fails with \u2018chart not found\u2019 error\u201d.</p>"},{"location":"3-troubleshooting/1-problem1/#context","title":"Context","text":"<p>Briefly describe when/where this issue happens: - What tool was being used? - What command was run? - What environment (e.g., Devbox, Docker, local cluster)? - Optional: Any preconditions or relevant setup</p>"},{"location":"3-troubleshooting/1-problem1/#symptoms","title":"Symptoms","text":"<p>List or describe the symptoms: - Error messages (you can add real output later) - Logs or console behavior - What \"broke\" or stopped working</p>"},{"location":"3-troubleshooting/1-problem1/#possible-causes","title":"Possible Causes","text":"<p>List 1\u20133 likely causes of this issue: - Misconfiguration - Dependency/version mismatch - Network or permissions issue</p>"},{"location":"3-troubleshooting/1-problem1/#resolution-if-available","title":"Resolution (If Available)","text":"<p>Leave this blank until you've confirmed a fix.</p>"},{"location":"3-troubleshooting/1-problem1/#workarounds-optional","title":"Workarounds (Optional)","text":"<p>Alternative approaches or partial fixes that helped during debugging.</p>"},{"location":"3-troubleshooting/1-problem1/#external-references","title":"External References","text":"<p>Useful links, docs, or forum threads: - Stack Overflow Thread - Official Docs - GitHub Issue</p>"},{"location":"3-troubleshooting/1-problem1/#notes","title":"Notes","text":"<ul> <li>Is this a recurring issue?</li> <li>Does it affect production or just local dev?</li> <li>Can this be caught with a precheck or task later?</li> </ul>"},{"location":"3-troubleshooting/2-problem2/","title":"Problem Title (Short and Specific)","text":"<p>A short one-liner summary of the issue, e.g., \u201cHelm chart fails with \u2018chart not found\u2019 error\u201d.</p>"},{"location":"3-troubleshooting/2-problem2/#context","title":"Context","text":"<p>Briefly describe when/where this issue happens: - What tool was being used? - What command was run? - What environment (e.g., Devbox, Docker, local cluster)? - Optional: Any preconditions or relevant setup</p>"},{"location":"3-troubleshooting/2-problem2/#symptoms","title":"Symptoms","text":"<p>List or describe the symptoms: - Error messages (you can add real output later) - Logs or console behavior - What \"broke\" or stopped working</p>"},{"location":"3-troubleshooting/2-problem2/#possible-causes","title":"Possible Causes","text":"<p>List 1\u20133 likely causes of this issue: - Misconfiguration - Dependency/version mismatch - Network or permissions issue</p>"},{"location":"3-troubleshooting/2-problem2/#resolution-if-available","title":"Resolution (If Available)","text":"<p>Leave this blank until you've confirmed a fix.</p>"},{"location":"3-troubleshooting/2-problem2/#workarounds-optional","title":"Workarounds (Optional)","text":"<p>Alternative approaches or partial fixes that helped during debugging.</p>"},{"location":"3-troubleshooting/2-problem2/#external-references","title":"External References","text":"<p>Useful links, docs, or forum threads: - Stack Overflow Thread - Official Docs - GitHub Issue</p>"},{"location":"3-troubleshooting/2-problem2/#notes","title":"Notes","text":"<ul> <li>Is this a recurring issue?</li> <li>Does it affect production or just local dev?</li> <li>Can this be caught with a precheck or task later?</li> </ul>"},{"location":"4-about/0-about/","title":"About Me","text":"<p>Dang, you really wanna know huh?</p> <p>I\u2019m Sean Njela, DevOpsSean. I'm a developer, engineer, and lifelong learner documenting my personal and professional projects.</p> <p>This site serves as a central hub for my technical work, built using MkDocs and organized to reflect real-world implementations, lessons learned, and ongoing exploration in areas like DevOps, infrastructure, automation, and system design.</p>"},{"location":"4-about/0-about/#why-this-exists","title":"Why This Exists","text":"<p>This documentation is part of an ongoing effort to:</p> <ul> <li>Capture complex project setups in a reusable, referenceable format</li> <li>Practice clear technical communication</li> <li>Save future-me from future-headaches</li> <li>Share knowledge with others who might stumble across this work</li> </ul> <p>Whether you're here to learn, debug, borrow ideas, or just browse, you're welcome.</p>"},{"location":"4-about/0-about/#tools-and-tech-i-often-work-with","title":"Tools and Tech I Often Work With","text":"<p>Some of the technologies you'll find across these projects:</p> <ul> <li>Containers: Docker, Kubernetes, Kind</li> <li>Infrastructure: Terraform, Helm, Devbox</li> <li>Automation: Taskfile, Make, CI/CD workflows</li> <li>Docs: MkDocs, markdown, GitHub Pages</li> <li>Languages: Python, Bash, YAML</li> </ul> <p>This stack evolves as I experiment and learn \u2014 not every project will use everything.</p>"},{"location":"4-about/0-about/#about-this-site","title":"About This Site","text":"<ul> <li>Built with <code>mkdocs-material</code></li> <li>Versioned using <code>mike</code></li> <li>Fully local-first and Git-managed</li> <li>Organized by topic, not tool \u2014 documentation follows the problem or pattern</li> </ul>"},{"location":"4-about/0-about/#contact","title":"Contact","text":"<p>I\u2019m always open to questions, feedback, or conversation:</p> <ul> <li>GitHub: @sean-njela</li> <li>Email: sean.njela@gmail.com</li> <li>Twitter/X: @devopssean</li> </ul> <p>Thanks for visiting !</p>"}]}